# åˆ›å»ºä½ çš„ç¬¬ä¸€ä¸ª FedAvg è”é‚¦å­¦ä¹ ä»»åŠ¡

## æ£€æŸ¥æ•°æ®

ä»»ä½•ä¸€ä¸ªå­¦ä¹ ä»»åŠ¡éƒ½éœ€è¦è¯»å…¥è®­ç»ƒæ•°æ®ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªä»»åŠ¡æ˜¯ç¡®è®¤å‚ä¸è¿ç®—çš„èŠ‚ç‚¹æ˜¯å¦èƒ½å¤ŸæˆåŠŸçš„è®¿é—®åˆ°è®­ç»ƒæ•°æ®ã€‚ç°å®ä¸–ç•Œçš„æ•°æ®åƒå˜ä¸‡åŒ–ï¼Œä½†æ˜¯åœ¨è¾“å…¥æ¨¡å‹ä¹‹å‰ï¼Œä¸€å®šä¼šé€šè¿‡ç‰¹å¾å·¥ç¨‹æ–¹æ³•è½¬æ¢ä¸ºé€‚åˆæ¨¡å‹çš„æ•°æ®ç»“æ„ã€‚å› æ­¤æˆ‘ä»¬çš„å…³æ³¨ç‚¹ä¸»è¦æœ‰ä¸¤ä¸ªï¼š
- æ˜¯å¦èƒ½å¤ŸæˆåŠŸè®¿é—®åˆ°è®­ç»ƒæ•°æ®ï¼Ÿ</br></br>
åœ¨è”é‚¦å­¦ä¹ ç¯å¢ƒä¸­è®¿é—®æ•°æ®çš„æ–¹å¼ä¸åœ¨ä¸­å¿ƒåŒ–çš„ç¯å¢ƒä¸­å¹¶æ²¡æœ‰å¤šå°‘ä¸åŒã€‚åªæ˜¯ç”±äºæ•°æ®æ‹¥æœ‰è€…çš„å¤šæ ·æ€§ï¼Œéœ€è¦è€ƒè™‘å»ºç«‹ä¸€ä¸ªç»Ÿä¸€çš„è§„èŒƒï¼Œå¹¶ä¸”å°½é‡æå‡åŠ è½½æ•°æ®ä»£ç çš„å…¼å®¹æ€§ï¼Œä»¥å°½å¯èƒ½æé«˜åŠ è½½æ•°æ®çš„æˆåŠŸç‡ã€‚  
æˆ‘ä»¬æ¨èä½ åœ¨ä»»åŠ¡æè¿°ä¸­æ˜ç¡®æŒ‡å®šæ•°æ®çš„å­˜å‚¨å’Œè®¿é—®æ–¹å¼ï¼Œä»¥å¸®åŠ©æ•°æ®æ‹¥æœ‰è€…æ˜ç¡®å¦‚ä½•å‡†å¤‡æ•°æ®ä»¥åŠåº”è¯¥å°†å®ƒä»¬å­˜æ”¾åœ¨å“ªé‡Œã€‚ï¼ˆ**éœ€è¦ä¿è¯æ•°æ®ä¾ç„¶ä¿å­˜äºæœ¬åœ°çš„å®‰å…¨ç¯å¢ƒä¸­ï¼Œå› æ­¤ä¸Šä¼ åˆ°ä¸€ä¸ªå¼€æ”¾çš„äº‘å­˜å‚¨ç¯å¢ƒå¹¶æä¾›é“¾æ¥å¯ä¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚**ï¼‰

- æ˜¯å¦èƒ½å¤ŸæˆåŠŸå°†è®­ç»ƒæ•°æ®è½¬æ¢ä¸ºé€‚åˆçš„æ•°æ®ç»“æ„ï¼Ÿ</br></br>
åœ¨è”é‚¦å­¦ä¹ ç¯å¢ƒä¸­ï¼ŒåŸå§‹æ•°æ®çš„æ ¼å¼å¯èƒ½å­˜åœ¨ä¸€äº›å·®å¼‚ï¼Œæ¯”å¦‚å›¾ç‰‡æ•°æ®å¯èƒ½ä½¿ç”¨äº†ä¸åŒçš„å°ºå¯¸æˆ–è€…æ ¼å¼ã€‚ä¸ºäº†å°½é‡æé«˜ç‰¹å¾è½¬æ¢çš„æ­£ç¡®ç‡ï¼Œä»£ç åº”å½“å°½é‡å…¼å®¹æ›´å¤šçš„å¯èƒ½æƒ…å†µã€‚
æˆ‘ä»¬æ¨èä½ åœ¨ä»»åŠ¡æè¿°ä¸­æ˜ç¡®æŒ‡å®šæ”¯æŒçš„æ•°æ®æ ¼å¼ï¼Œä»¥å¸®åŠ©æ•°æ®æ‹¥æœ‰è€…æ˜ç¡®å¦‚ä½•å¯¹æ•°æ®åšé¢„å¤„ç†ã€‚å¦‚æœå¯èƒ½çš„è¯ï¼Œä¹Ÿå¯ä»¥é™„å¸¦ä¸€äº›æ•°æ®å¤„ç†çš„æŒ‡å¯¼ã€‚

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªéªŒè¯è®¿é—®å’Œè½¬æ¢æ•°æ®çš„æ¨¡æ¿ï¼Œä½ å¯ä»¥åœ¨è¿™ä¸ªæ¨¡æ¿çš„åŸºç¡€ä¸Šä¿®æ”¹ï¼Œä»¥é€‚åº”ä½ çš„ä»»åŠ¡éœ€è¦ã€‚

```python
import logging
import os

import torchvision
from torch.utils.data import DataLoader

_logger = logging.getLogger("app")


class DatasetVerify(object):

    def __init__(self, task_id, current_node):
        self.task_id = task_id
        self.current_node = current_node

    def run(self) -> bool:
        """æ•°æ®é›†çš„æ ¡éªŒå…·ä½“é€»è¾‘."""
        _logger.info(f"start dataset verification for task {self.task_id} on {self.current_node}")
        root_dir = '/data/MNIST/'
        return self._touch_data(root_dir) and self._load_data(root_dir)

    def _touch_data(self, root_dir: str) -> bool:
        file_list = [
            't10k-images-idx3-ubyte',
            't10k-images-idx3-ubyte.gz',
            't10k-labels-idx1-ubyte',
            't10k-labels-idx1-ubyte.gz',
            'train-images-idx3-ubyte',
            'train-images-idx3-ubyte.gz',
            'train-labels-idx1-ubyte',
            'train-labels-idx1-ubyte.gz'
        ]
        full_paths = [os.path.join(root_dir, _file) for _file in file_list]
        return all(os.path.exists(_file) and os.path.isfile(_file)
                    for _file in full_paths)

    def _load_data(self, root_dir: str) -> bool:
        data_loader = DataLoader(
            torchvision.datasets.MNIST(
                root_dir,
                train=True,
                download=False,
                transform=torchvision.transforms.Compose([
                    torchvision.transforms.ToTensor(),
                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
                ])
            )
        )
        return data_loader is not None and len(data_loader) > 0
```

python æ–‡ä»¶ä¸­å®šä¹‰çš„ç±»åå¿…é¡»æ˜¯ â€œDatasetVerifyâ€ã€‚å…¶ä¸­çš„ â€œ\_\_init__â€ åˆå§‹åŒ–æ–¹æ³•çš„å‚æ•°åˆ—è¡¨ä¸å¯ä»¥ä¿®æ”¹ï¼Œå¦åˆ™ä¼šå¯¼è‡´ä»£ç åŠ è½½å¤±è´¥ã€‚â€œrunâ€ æ–¹æ³•ä¸­çš„é€»è¾‘ç”¨äºæ£€æŸ¥æ˜¯å¦èƒ½å¤Ÿè®¿é—®åˆ°æ•°æ®ä»¥åŠèƒ½å¤Ÿæ­£ç¡®çš„å°†æ•°æ®è½¬åŒ–ä¸ºç‰¹å¾ï¼Œä½ å¯ä»¥æ ¹æ®ä»»åŠ¡éœ€è¦ç¼–å†™è‡ªå·±çš„æ£€æŸ¥é€»è¾‘ã€‚

å®é™…ä¸Šï¼Œä¸¤æ­¥æ£€æŸ¥éƒ½ä¸æ˜¯å¿…é¡»çš„ï¼Œä»¥æä¾›æœ€å¤§çš„çµæ´»æ€§ã€‚ä½†æ˜¯æˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½ å°½å¯èƒ½å®ç°å®ƒä»¬ã€‚å¦åˆ™å¯èƒ½å¯¼è‡´è¿è¡Œæ—¶é”™è¯¯ï¼Œå±Šæ—¶è°ƒè¯•çš„ä»£ä»·å¯èƒ½ä¼šé«˜å‡ºå¾ˆå¤šã€‚

## åˆ›å»ºä»»åŠ¡

ç™»å½• [AlphaMed ç®¡ç†é¡µé¢](http://81.70.132.120/)ã€‚æ–°å»ºä¸€ä¸ªè®¡ç®—ä»»åŠ¡ï¼Œåœ¨â€œè”é‚¦ç±»å‹â€é€‰é¡¹ä¸­é€‰æ‹©â€œæ¨ªå‘â€ï¼Œå¹¶æ ¹æ®éœ€è¦å¡«å†™å…¶å®ƒä»»åŠ¡ä¿¡æ¯ï¼Œç„¶åç‚¹å‡»â€œåˆ›å»ºä»»åŠ¡â€ã€‚

åˆ›å»ºä»»åŠ¡æ—¶éœ€è¦ä¸Šä¼ æˆ‘ä»¬åœ¨â€œæ£€æŸ¥æ•°æ®â€ç« èŠ‚ç¼–å†™çš„ python ä»£ç æ–‡ä»¶ï¼Œä»»åŠ¡ç®¡ç†å™¨å°†ä½¿ç”¨è¿™äº›é€»è¾‘æ£€æŸ¥æ¯ä¸€ä¸ªå‚ä¸è®¡ç®—çš„æ•°æ®èŠ‚ç‚¹ï¼Œä»¥ç¡®ä¿è®¡ç®—ä»»åŠ¡å¯åŠ¨åæ•°æ®å¯ç”¨ã€‚

## å®šä¹‰ä»»åŠ¡ç»†èŠ‚

ç°åœ¨ï¼Œå¯ä»¥å®šä¹‰æˆ‘ä»¬çš„è®¡ç®—ä»»åŠ¡ç»†èŠ‚äº†ã€‚æˆ‘ä»¬å‡å®šä½ å·²ç»ç†Ÿæ‚‰äº†æ·±åº¦å­¦ä¹ çš„ç›¸å…³çŸ¥è¯†ï¼Œå¹¶ä¸”å…·å¤‡äº†åˆ©ç”¨ PyTorch æ¡†æ¶å°†æ¨¡å‹æ¦‚å¿µè½¬åŒ–ä¸ºä»£ç çš„èƒ½åŠ›ã€‚è‹¥éå¦‚æ­¤ï¼Œå»ºè®®ä½ å…ˆå»å­¦ä¹ ä¸€ä¸‹è¿™äº›çŸ¥è¯†ï¼Œç„¶åå†å›æ¥ç»§ç»­åé¢çš„æ—…ç¨‹ã€‚

è¦å®šä¹‰ä¸€ä¸ª FedAvg è”é‚¦å­¦ä¹ ä»»åŠ¡ï¼Œä½ éœ€è¦å®šä¹‰ä¸€ä¸ª â€œFedAvgSchedulerâ€ çš„å­ç±»ï¼Œå¹¶å®ç°å…¶ä¸­çš„ä¸€äº›æ–¹æ³•ã€‚ä½ å¯ä»¥åœ¨æˆ‘ä»¬çš„ Notebook ç¼–è¾‘æ¡†ä¸­åˆ›å»ºä½ çš„ç¬¬ä¸€ä¸ª FedAvg è”é‚¦å­¦ä¹ ä»»åŠ¡ï¼Œå°±åƒè¿™æ ·ï¼š

```python
import os
from typing import Any, Dict

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torch.utils.data import DataLoader

from alphafed import logger
from alphafed.fed_avg import FedAvgScheduler

class DemoScheduler(FedAvgScheduler):
    ...
```

FedAvgScheduler æ¥æ”¶ä¸€äº›åˆå§‹åŒ–å‚æ•°ï¼Œä¸€äº›ä¸»è¦çš„å‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š
- min_clientsï¼ˆå¿…å¡«å‚æ•°ï¼‰ï¼šæ¯è½®è®­ç»ƒä¸­æœ€å°‘åŒ…å«çš„æ•°æ®å‚ä¸æ–¹æ•°é‡ï¼Œæ•°é‡ä¸è¶³ä¼šå¯¼è‡´è®­ç»ƒå¤±è´¥ï¼›
- max_clientsï¼ˆå¿…å¡«å‚æ•°ï¼‰ï¼šæ¯è½®è®­ç»ƒä¸­æœ€å¤šåŒ…å«çš„æ•°æ®å‚ä¸æ–¹æ•°é‡ï¼Œè¶…å‡ºæ—¶ä¼šå°†å¤šä½™çš„æ•°æ®å‚ä¸æ–¹æ’é™¤ï¼›
- max_roundsï¼ˆå¿…å¡«å‚æ•°ï¼‰ï¼šæœ€å¤šè®­ç»ƒè½®æ¬¡ï¼Œè¾¾åˆ°æ­¤è®­ç»ƒè½®æ¬¡åä»»åŠ¡ç»“æŸï¼›
- nameï¼ˆå¯é€‰å‚æ•°ï¼‰ï¼šè®­ç»ƒä»»åŠ¡çš„åç§°ï¼Œé»˜è®¤ä¸ºä»»åŠ¡ IDï¼›
- merge_epochsï¼ˆå¯é€‰å‚æ•°ï¼‰ï¼šæ¯ä¸€è½®èšåˆå‚æ•°ä¹‹å‰ï¼Œåœ¨æœ¬åœ°æ‰§è¡Œå¤šå°‘ä¸ªè®­ç»ƒè½®æ¬¡ï¼Œé»˜è®¤ä¸º 1ï¼›
- calculation_timeoutï¼ˆå¯é€‰å‚æ•°ï¼‰ï¼šè®¡ç®—è¶…æ—¶æ—¶é—´ï¼Œå¼€å§‹æ‰§è¡Œæœ¬åœ°è®­ç»ƒåï¼Œåœ¨æ­¤æ—¶é—´å†…æ²¡æœ‰æäº¤å‚æ•°æ›´æ–°ç»“æœå°†è¢«è§†ä¸ºè¶…æ—¶ï¼›
- log_roundsï¼ˆå¯é€‰å‚æ•°ï¼‰ï¼šæ¯éš”å‡ è½®è®­ç»ƒåï¼Œæ‰§è¡Œä¸€æ¬¡æµ‹è¯•å¹¶è®°å½•å½“å‰æ¨¡å‹æµ‹è¯•ç»“æœï¼›
 
æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥å®Œæˆå®ƒã€‚

### å®šä¹‰æ¨¡å‹

ç¬¬ä¸€ä¸ªä»»åŠ¡æ˜¯å®ç° â€œmake\_modelâ€ æ–¹æ³•ï¼Œå®ƒå°†è¿”å›ä»»åŠ¡è®¡ç®—æ—¶ä½¿ç”¨çš„æ¨¡å‹å¯¹è±¡ã€‚å¹¸è¿çš„æ˜¯ï¼Œè¿™å°±æ˜¯ä¸ªæ™®é€šçš„ torch.nn.Module å¯¹è±¡ã€‚

```python
class ConvNet(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(in_features=320, out_features=50)
        self.fc2 = nn.Linear(in_features=50, out_features=10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=-1)


def make_model(self) -> nn.Module:
    model = ConvNet()
    self.optimizer = torch.optim.SGD(model.parameters(),
                                     lr=self.learning_rate,
                                     momentum=self.momentum)
    return model
```

ä»”ç»†åˆ†æä»£ç ä¼šå‘ç°ï¼Œå…¶ä¸­ä½¿ç”¨äº†ä¸¤ä¸ªè¿˜æœªå®šä¹‰çš„å¯¹è±¡å±æ€§ï¼šâ€œself.learning\_rateâ€ï¼Œâ€œself.momentumâ€ã€‚è¿™ä¸¤ä¸ªå±æ€§æ˜¯åœ¨åˆå§‹åŒ–å¯¹è±¡çš„æ—¶å€™è¢«èµ‹å€¼çš„ï¼ŒæŒ‚åœ¨ â€œselfâ€ ä¸Šçš„å¥½å¤„æ˜¯ï¼Œå½“æˆ‘ä»¬åœ¨å…¶å®ƒæ–¹æ³•ä¸­éœ€è¦è®¿é—®å®ƒä»¬çš„æ—¶å€™ï¼Œå®ƒä»¬éšæ—¶éƒ½åœ¨ã€‚åé¢æˆ‘ä»¬ä¼šè¯¦ç»†ä»‹ç»ï¼Œç›®å‰å¯ä»¥æš‚æ—¶å¿½ç•¥è¿™ä¸ªé—®é¢˜ã€‚å½“ç„¶ä½ ä¹Ÿå¯ä»¥åœ¨ â€œmake\_modelâ€ æ–¹æ³•ä¸­ç›´æ¥å®šä¹‰éœ€è¦çš„ä»»ä½•å˜é‡ã€‚

å¦‚æœä½ è¿˜éœ€è¦ä¸€ä¸ªä¼˜åŒ–å™¨ï¼Œä¹Ÿæ¨èåœ¨ â€œmake\_modelâ€ æ–¹æ³•ä¸­å®šä¹‰ï¼Œå¹¶æŠŠå®ƒæŒ‚è½½åœ¨ â€œselfâ€ ä¸Šã€‚è¿™æ ·åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­å°±å¯ä»¥æ–¹ä¾¿çš„ä½¿ç”¨è¿™ä¸ªä¼˜åŒ–å™¨äº†ã€‚

### åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨

ç¬¬äºŒä¸ªä»»åŠ¡æ˜¯å¤„ç†æ•°æ®çš„åŠ è½½ï¼Œéœ€è¦å®ç° â€œmake\_train\_dataloaderâ€ å’Œ â€œmake\_test\_dataloaderâ€ ä¸¤ä¸ªæ–¹æ³•ï¼Œå®ƒä»¬å°†åˆ†åˆ«è¿”å›è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®çš„æ•°æ®åŠ è½½å™¨å¯¹è±¡ã€‚åŒæ ·çš„ï¼Œè¿™ä¸¤ä¸ªå¯¹è±¡éƒ½æ˜¯æ™®é€šçš„ torch.utils.data.DataLoader å¯¹è±¡ï¼Œæˆ‘ä»¬åº”è¯¥å¯¹æ­¤å¾ˆç†Ÿæ‚‰äº†ã€‚

```python
def make_train_dataloader(self) -> DataLoader:
    return DataLoader(
        torchvision.datasets.MNIST(
            os.path.join('root_path', 'data'),
            train=True,
            download=True,
            transform=torchvision.transforms.Compose([
                torchvision.transforms.ToTensor(),
                torchvision.transforms.Normalize((0.1307,), (0.3081,))
            ])
        ),
        batch_size=self.batch_size,
        shuffle=True
    )

def make_test_dataloader(self) -> DataLoader:
    return DataLoader(
        torchvision.datasets.MNIST(
            os.path.join('root_path', 'data'),
            train=False,
            download=True,
            transform=torchvision.transforms.Compose([
                torchvision.transforms.ToTensor(),
                torchvision.transforms.Normalize((0.1307,), (0.3081,))
            ])
        ),
        batch_size=self.batch_size,
        shuffle=False
    )
```

### è·å–å’ŒåŠ è½½å‚æ•°

æˆ‘ä»¬çš„è®¡ç®—ç›®æ ‡æ˜¯æ›´æ–°æ¨¡å‹çš„ç›¸å…³å‚æ•°ï¼Œæ‰€ä»¥æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å®ç° â€œstate\_dictâ€ å’Œ â€œload\_state\_dictâ€ æ–¹æ³•ï¼Œå®ƒä»¬åˆ†åˆ«ç”¨æ¥è·å–å’ŒåŠ è½½éœ€è¦æ›´æ–°çš„å‚æ•°ã€‚è¿™ä¸¤ä¸ªæ–¹æ³•éœ€è¦é…åˆå·¥ä½œï¼Œäº’ç›¸å¯ä»¥è§†ä¸ºå¯¹æ–¹çš„é•œåƒã€‚

```python
def state_dict(self) -> Dict[str, torch.Tensor]:
    return self.model.state_dict()

def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
    self.model.load_state_dict(state_dict)
```

å½“ç„¶ä½ ä¹Ÿå¯ä»¥åœ¨ â€œstate\_dictâ€ æ–¹æ³•ä¸­è¿”å›å…¶å®ƒéœ€è¦å­¦ä¹ çš„å‚æ•°ï¼Œæ¯”å¦‚ä¼˜åŒ–å™¨çš„å‚æ•°ï¼Œå¹¶åœ¨ â€œload\_state\_dictâ€ æ–¹æ³•ä¸­å°†å®ƒä»¬é‡æ–°åŠ è½½åˆ°ä¼˜åŒ–å™¨ä¸­ã€‚â€œstate\_dictâ€ è¿”å›çš„æ‰€æœ‰å‚æ•°éƒ½éµå¾ª FedAvg ç®—æ³•çš„å‚æ•°å¤„ç†æµç¨‹è¿›è¡Œè®¡ç®—å’Œæ›´æ–°ï¼Œå› æ­¤è¯·ç¡®ä¿åªè¿”å›å…¼å®¹çš„å‚æ•°ç±»å‹ã€‚å¦‚æœè¿”å›äº†å¦‚ torch.bool ç±»å‹çš„å‚æ•°ï¼Œå…¶æ›´æ–°åçš„å€¼å¯èƒ½ä¸ç¬¦åˆä½ çš„é¢„æœŸï¼Œç”šè‡³å¯èƒ½å¼•èµ·ç¨‹åºé”™è¯¯ã€‚

### å®šä¹‰è®­ç»ƒé€»è¾‘

ç°åœ¨ï¼Œå¯ä»¥å®šä¹‰æˆ‘ä»¬çš„è®­ç»ƒè¿‡ç¨‹äº†ã€‚å¥½æ¶ˆæ¯æ˜¯ï¼Œä¸åœ¨æœ¬åœ°æ‰§è¡Œè®­ç»ƒçš„æ–¹å¼ä¸€æ¨¡ä¸€æ ·ã€‚

```python
def train(self) -> None:
    self.model.train()
    train_loader = self.make_train_dataloader()
    for data, labels in train_loader:
        data: torch.Tensor
        labels: torch.Tensor
        data, labels = data.to(self.device), labels.to(self.device)
        self.optimizer.zero_grad()
        output = self.model(data)
        loss = F.nll_loss(output, labels)
        loss.backward()
        self.optimizer.step()
```

### å®šä¹‰æµ‹è¯•é€»è¾‘

ä¸ºäº†éªŒè¯æ¨¡å‹çš„è®­ç»ƒæˆæœï¼Œæˆ‘ä»¬éœ€è¦åœ¨å¿…è¦çš„æ—¶å€™å¯¹å½“å‰çš„æœ€æ–°å‚æ•°åšä¸€äº›æµ‹è¯•ã€‚åŒæ ·çš„ï¼Œæµ‹è¯•çš„æ–¹å¼ä¸æœ¬åœ°æµ‹è¯•ä¹Ÿæ˜¯ä¸€æ¨¡ä¸€æ ·çš„ã€‚åªæ˜¯åœ¨æµ‹è¯•ç»“æŸæ—¶ï¼Œä½ éœ€è¦å°†å…³å¿ƒçš„æµ‹è¯•ç»“æœè¿”å›ï¼Œä»¥ä¾¿ç³»ç»Ÿä¸ºä½ å±•ç¤ºè¿™äº›ç»“æœã€‚é™¤æ­¤ä¹‹å¤–ï¼Œæ²¡æœ‰ä»»ä½•ç‰¹æ®Šä¹‹å¤„ã€‚

```python
def test(self) -> Dict[str, Any]:
    self.model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        test_loader = self.make_test_dataloader()
        for data, labels in test_loader:
            data: torch.Tensor
            labels: torch.Tensor
            data, labels = data.to(self.device), labels.to(self.device)
            output: torch.Tensor = self.model(data)
            test_loss += F.nll_loss(output, labels, reduction='sum').item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(labels.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)
    accuracy = correct / len(test_loader.dataset)
    correct_rate = 100. * accuracy
    logger.info(f'Test set: Average loss: {test_loss:.4f}')
    logger.info(
        f'Test set: Accuracy: {accuracy} ({correct_rate:.2f}%)'
    )
    return {
        'average loss': test_loss,
        'accuracy': accuracy,
        'correct_rate': correct_rate
    }
```

å¥½äº†ï¼Œåˆ°æ­¤ä¸ºæ­¢ï¼Œæ‰€æœ‰å¿…é¡»çš„å·¥ä½œéƒ½å·²ç»åšå®Œäº†ã€‚ä¸‹é¢çš„æ­¥éª¤æ˜¯å¯é€‰çš„ï¼Œä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€è¦é€‰æ‹©å®ç°ã€‚å½“ç„¶ï¼Œä¹Ÿå¯ä»¥å…¨éƒ¨è·³è¿‡ã€‚

## å®šä¹‰å¯é€‰çš„ä»»åŠ¡ç»†èŠ‚

### æ·»åŠ è‡ªå·±çš„åˆå§‹åŒ–é…ç½®

åœ¨å¤§å¤šæ•°ç°å®åœºæ™¯ä¸­ï¼Œé»˜è®¤çš„åˆå§‹åŒ–é…ç½®é¡¹å¯èƒ½éƒ½ä¸è¶³ä»¥æ»¡è¶³ä½ çš„å…¨éƒ¨éœ€æ±‚ã€‚ä¾æ®ä½ ä½¿ç”¨çš„æ¨¡å‹å’Œè®­ç»ƒæ–¹æ³•ï¼Œä½ å¯èƒ½éœ€è¦åŠ å…¥æ›´å¤šçš„å‚æ•°ä»¥è·å¾—æ›´å¥½çš„è®­ç»ƒæ•ˆæœã€‚è¦å®ç°è¿™ä¸€ç‚¹å¾ˆç®€å•ï¼Œå°±åƒæ‰€æœ‰æ™®é€šçš„ python ç±»å®šä¹‰ä¸€æ ·ï¼Œä½ åªéœ€è¦åœ¨ â€œ\_\_init__â€ æ–¹æ³•ä¸­åšä¸€äº›å¿…è¦çš„å¤„ç†ã€‚

```python
def __init__(self,
             min_clients: int,
             max_clients: int,
             name: str = None,
             max_rounds: int = 0,
             merge_epoch: int = 1,
             calculation_timeout: int = 300,
             log_rounds: int = 0,
             is_centralized: bool = True,
             batch_size: int = 64,
             learning_rate: float = 0.01,
             momentum: float = 0.5) -> None:
    super().__init__(min_clients=min_clients,
                     max_clients=max_clients,
                     name=name,
                     max_rounds=max_rounds,
                     merge_epochs=merge_epoch,
                     calculation_timeout=calculation_timeout,
                     log_rounds=log_rounds,
                     is_centralized=is_centralized)
    self.batch_size = batch_size
    self.learning_rate = learning_rate
    self.momentum = momentum

    self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    self.seed = 42
    torch.manual_seed(self.seed)
```

è¿˜è®°å¾—æˆ‘ä»¬ä¹‹å‰é‡åˆ°çš„ â€œself.learning\_rateâ€ã€â€œself.momentumâ€ å‚æ•°å—ï¼Ÿç°åœ¨ä½ çŸ¥é“å®ƒä»¬æ˜¯æ€ä¹ˆæ¥çš„äº†å§ã€‚åœ¨ç°å®åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦æ·»åŠ å¤šä¸ªæœ‰åŠ©äºæ¨¡å‹è®­ç»ƒçš„å‚æ•°ã€‚ä¹Ÿè®¸å…¶ä¸­æœ‰ä¸€äº›æ˜¯éœ€è¦åœ¨å¤–éƒ¨æ§åˆ¶çš„ï¼Œæ¯”å¦‚ â€œbatch\_sizeâ€ã€â€œlearning\_rateâ€ã€â€œmomentumâ€ï¼Œä½ å¯ä»¥æŠŠå®ƒä»¬åŠ å…¥åˆå§‹åŒ–çš„å‚æ•°åˆ—è¡¨ä¸­ã€‚ä¹Ÿè®¸è¿˜æœ‰ä¸€äº›å‚æ•°ä¸å¸Œæœ›å—åˆ°å¤–éƒ¨ç¯å¢ƒçš„å½±å“ï¼Œæ¯”å¦‚ â€œdeviceâ€ã€â€œseedâ€ï¼Œé‚£å°±æŠŠå®ƒä»¬è—åœ¨ â€œ\_\_init__â€ å†…éƒ¨å¥½äº†ã€‚è¿™æ ·å¯ä»¥é¿å…å¤–éƒ¨ä½¿ç”¨è€…é”™è¯¯çš„è®¾ç½®è¿™äº›å‚æ•°ï¼ŒåŒæ—¶è¿˜èƒ½ä¿è¯è®­ç»ƒè¿‡ç¨‹ä¸­éšæ—¶å¯ä»¥è®¿é—®åˆ°è¿™äº›å‚æ•°ã€‚

**è¯·è®°ä½ï¼Œæ‰€æœ‰è¿™äº›é™„åŠ çš„å‚æ•°ï¼Œéƒ½éœ€è¦ä½ è‡ªå·±æ¥ç®¡ç†ã€‚**

### éªŒè¯è¿è¡Œç¯å¢ƒ

åœ¨å®é™…è¿è¡Œä¹‹å‰ï¼Œå¯èƒ½ä¼šå¸Œæœ›å¯¹è¿è¡Œç¯å¢ƒå†åšä¸€äº›æ£€æŸ¥ï¼Œå¸®åŠ©å‘ç°ä¸€äº›æ½œåœ¨çš„é”™è¯¯ã€‚å¦‚æœä½ ç¡®å®æœ‰æ­¤éœ€æ±‚ï¼Œå¯ä»¥å®ç° â€œvalidate\_contextâ€ æ–¹æ³•ï¼Œæ·»åŠ ä»»ä½•ä½ éœ€è¦çš„æ£€æŸ¥é€»è¾‘ï¼Œæˆ–è€…è¾“å‡ºä¸€äº›ç¯å¢ƒä¿¡æ¯ä»¥åˆ©äºæ£€æŸ¥é—®é¢˜ã€‚ä½†æ˜¯éœ€è¦ç•™æ„ï¼Œ**ä¸è¦å¿˜è®°å…ˆè°ƒç”¨çˆ¶ç±»çš„æ–¹æ³•ï¼Œå¦åˆ™ä¼šå¯¼è‡´è¿è¡Œæ—¶é”™è¯¯ã€‚**

å¦‚æœä½ æ²¡æœ‰è¿™æ–¹é¢çš„éœ€æ±‚ï¼Œåˆ™å¯ä»¥ç›´æ¥è·³è¿‡è¿™ä¸€æ­¥ã€‚

```python
def validate_context(self):
    super().validate_context()
    train_loader = self.make_train_dataloader()
    assert train_loader and len(train_loader) > 0
    logger.info(f'There are {len(train_loader)} samples for training.')
    test_loader = self.make_train_dataloader()
    assert test_loader and len(test_loader) > 0
    logger.info(f'There are {len(test_loader)} samples for testing.')
```

### æ§åˆ¶ä»»åŠ¡å®Œæˆçš„æ¡ä»¶

é»˜è®¤æƒ…å†µä¸‹ï¼Œè®¡ç®—ä»»åŠ¡å°†åœ¨å®Œæˆ max\_rounds è½®çš„è®­ç»ƒä¹‹åè‡ªåŠ¨å®Œæˆã€‚åœ¨ä¸€äº›æ›´å¤æ‚çš„åœºæ™¯ä¸­ï¼Œä½ å¯èƒ½å¸Œæœ›ä½¿ç”¨ä¸€äº›æ›´å¤æ‚çš„é€»è¾‘ä»¥åˆ¤æ–­æ˜¯å¦è¦ç»“æŸè®­ç»ƒï¼Œç”šè‡³å¯èƒ½å¸Œæœ›è®­ç»ƒæ°¸è¿œæ‰§è¡Œä¸‹å»ã€‚æ­¤æ—¶å°±éœ€è¦ä¿®æ”¹ â€œis\_task\_finishedâ€ æ–¹æ³•çš„åˆ¤æ–­é€»è¾‘äº†ï¼Œå°†å®ƒä¿®æ”¹æˆä½ å¸Œæœ›çš„æ ·å­å§ã€‚

```python
def is_task_finished(self) -> bool:
    """By default true if reach the max rounds configured."""
    return self._is_reach_max_rounds()
```

# å¯åŠ¨ä»»åŠ¡

è‡³æ­¤ï¼Œæ‰€æœ‰ä½ éœ€è¦äº†è§£çš„çŸ¥è¯†éƒ½å·²ç»ä»‹ç»å®Œäº†ã€‚åœ¨çœŸæ­£å¯åŠ¨æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªä»»åŠ¡ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆæŠŠå‰é¢é‚£äº›é›¶æ•£çš„æ–¹æ³•å®ç°æ•´ç†ä¸€ä¸‹ï¼Œæ±‡æ€»åˆ°ä¸€èµ·ã€‚ç„¶åï¼Œä½ è¿˜éœ€è¦åœ¨ä»»åŠ¡ç®¡ç†é¡µé¢ä¸­æŸ¥çœ‹ä¸€ä¸‹å½“å‰ä»»åŠ¡çš„ IDã€‚ä»»åŠ¡ ID å¯ä»¥åœ¨ Playgroud é¡µé¢æ‰¾åˆ°å¹¶å¤åˆ¶ï¼Œå¦‚ä¸‹å›¾ï¼š
![è·å–å½“å‰ä»»åŠ¡ ID](./task_id.png)

ç°åœ¨ï¼Œå‘å°„ä½ çš„ç¬¬ä¸€æš ğŸš€ å§ ...

```python
import os
from typing import Any, Dict

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torch.utils.data import DataLoader

from alphafed import logger
from alphafed.fed_avg import FedAvgScheduler


class ConvNet(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(in_features=320, out_features=50)
        self.fc2 = nn.Linear(in_features=50, out_features=10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=-1)


class DemoScheduler(FedAvgScheduler):

    def __init__(self,
                 min_clients: int,
                 max_clients: int,
                 name: str = None,
                 max_rounds: int = 0,
                 merge_epoch: int = 1,
                 calculation_timeout: int = 300,
                 log_rounds: int = 0,
                 is_centralized: bool = True,
                 batch_size: int = 64,
                 learning_rate: float = 0.01,
                 momentum: float = 0.5) -> None:
        super().__init__(min_clients=min_clients,
                         max_clients=max_clients,
                         name=name,
                         max_rounds=max_rounds,
                         merge_epochs=merge_epoch,
                         calculation_timeout=calculation_timeout,
                         log_rounds=log_rounds,
                         is_centralized=is_centralized)
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.momentum = momentum

        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.seed = 42
        torch.manual_seed(self.seed)

    def make_model(self) -> nn.Module:
        model = ConvNet()
        self.optimizer = torch.optim.SGD(model.parameters(),
                                         lr=self.learning_rate,
                                         momentum=self.momentum)
        return model

    def make_train_dataloader(self) -> DataLoader:
        return DataLoader(
            torchvision.datasets.MNIST(
                os.path.join(self.name, 'data'),
                train=True,
                download=True,
                transform=torchvision.transforms.Compose([
                    torchvision.transforms.ToTensor(),
                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
                ])
            ),
            batch_size=self.batch_size,
            shuffle=True
        )

    def make_test_dataloader(self) -> DataLoader:
        return DataLoader(
            torchvision.datasets.MNIST(
                os.path.join(self.name, 'data'),
                train=False,
                download=True,
                transform=torchvision.transforms.Compose([
                    torchvision.transforms.ToTensor(),
                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
                ])
            ),
            batch_size=self.batch_size,
            shuffle=False
        )

    def state_dict(self) -> Dict[str, torch.Tensor]:
        return self.model.state_dict()

    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
        self.model.load_state_dict(state_dict)

    def validate_context(self):
        super().validate_context()
        train_loader = self.make_train_dataloader()
        assert train_loader and len(train_loader) > 0
        logger.info(f'There are {len(train_loader)} samples for training.')
        test_loader = self.make_train_dataloader()
        assert test_loader and len(test_loader) > 0
        logger.info(f'There are {len(test_loader)} samples for testing.')

    def train(self) -> None:
        self.model.train()
        train_loader = self.make_train_dataloader()
        for data, labels in train_loader:
            data: torch.Tensor
            labels: torch.Tensor
            data, labels = data.to(self.device), labels.to(self.device)
            self.optimizer.zero_grad()
            output = self.model(data)
            loss = F.nll_loss(output, labels)
            loss.backward()
            self.optimizer.step()

    def test(self) -> Dict[str, Any]:
        self.model.eval()
        test_loss = 0
        correct = 0
        with torch.no_grad():
            test_loader = self.make_test_dataloader()
            for data, labels in test_loader:
                data: torch.Tensor
                labels: torch.Tensor
                data, labels = data.to(self.device), labels.to(self.device)
                output: torch.Tensor = self.model(data)
                test_loss += F.nll_loss(output, labels, reduction='sum').item()
                pred = output.max(1, keepdim=True)[1]
                correct += pred.eq(labels.view_as(pred)).sum().item()

        test_loss /= len(test_loader.dataset)
        accuracy = correct / len(test_loader.dataset)
        correct_rate = 100. * accuracy
        logger.info(f'Test set: Average loss: {test_loss:.4f}')
        logger.info(
            f'Test set: Accuracy: {accuracy} ({correct_rate:.2f}%)'
        )
        return {
            'average loss': test_loss,
            'accuracy': accuracy,
            'correct_rate': correct_rate
        }

scheduler = DemoScheduler(min_clients=2,
                          max_clients=3,
                          name='demo_task',
                          max_rounds=5,
                          log_rounds=1,
                          calculation_timeout=120)
scheduler.launch_task(task_id='YOUR_TASK_ID')
```
