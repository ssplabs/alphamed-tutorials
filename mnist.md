# åˆ›å»ºä½ çš„ç¬¬ä¸€ä¸ª FedAvg è”é‚¦å­¦ä¹ ä»»åŠ¡

## æ£€æŸ¥æ•°æ®

ä»»ä½•ä¸€ä¸ªå­¦ä¹ ä»»åŠ¡éƒ½éœ€è¦è¯»å…¥è®­ç»ƒæ•°æ®ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªä»»åŠ¡æ˜¯ç¡®è®¤å‚ä¸è¿ç®—çš„èŠ‚ç‚¹æ˜¯å¦èƒ½å¤ŸæˆåŠŸçš„è®¿é—®åˆ°è®­ç»ƒæ•°æ®ã€‚ç°å®ä¸–ç•Œçš„æ•°æ®åƒå˜ä¸‡åŒ–ï¼Œä½†æ˜¯åœ¨è¾“å…¥æ¨¡å‹ä¹‹å‰ï¼Œä¸€å®šä¼šé€šè¿‡ç‰¹å¾å·¥ç¨‹æ–¹æ³•è½¬æ¢ä¸ºé€‚åˆæ¨¡å‹çš„æ•°æ®ç»“æ„ã€‚å› æ­¤æˆ‘ä»¬çš„å…³æ³¨ç‚¹ä¸»è¦æœ‰ä¸¤ä¸ªï¼š
- æ˜¯å¦èƒ½å¤ŸæˆåŠŸè®¿é—®åˆ°è®­ç»ƒæ•°æ®ï¼Ÿ</br></br>
åœ¨è”é‚¦å­¦ä¹ ç¯å¢ƒä¸­è®¿é—®æ•°æ®çš„æ–¹å¼ä¸åœ¨ä¸­å¿ƒåŒ–çš„ç¯å¢ƒä¸­å¹¶æ²¡æœ‰å¤šå°‘ä¸åŒã€‚åªæ˜¯ç”±äºæ•°æ®æ‹¥æœ‰è€…çš„å¤šæ ·æ€§ï¼Œéœ€è¦è€ƒè™‘å»ºç«‹ä¸€ä¸ªç»Ÿä¸€çš„è§„èŒƒï¼Œå¹¶ä¸”å°½é‡æå‡åŠ è½½æ•°æ®ä»£ç çš„å…¼å®¹æ€§ï¼Œä»¥å°½å¯èƒ½æé«˜åŠ è½½æ•°æ®çš„æˆåŠŸç‡ã€‚  
æˆ‘ä»¬æ¨èä½ åœ¨ä»»åŠ¡æè¿°ä¸­æ˜ç¡®æŒ‡å®šæ•°æ®çš„å­˜å‚¨å’Œè®¿é—®æ–¹å¼ï¼Œä»¥å¸®åŠ©æ•°æ®æ‹¥æœ‰è€…æ˜ç¡®å¦‚ä½•å‡†å¤‡æ•°æ®ä»¥åŠåº”è¯¥å°†å®ƒä»¬å­˜æ”¾åœ¨å“ªé‡Œã€‚ï¼ˆ**éœ€è¦ä¿è¯æ•°æ®ä¾ç„¶ä¿å­˜äºæœ¬åœ°çš„å®‰å…¨ç¯å¢ƒä¸­ï¼Œå› æ­¤ä¸Šä¼ åˆ°ä¸€ä¸ªå¼€æ”¾çš„äº‘å­˜å‚¨ç¯å¢ƒå¹¶æä¾›é“¾æ¥å¯ä¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚**ï¼‰

- æ˜¯å¦èƒ½å¤ŸæˆåŠŸå°†è®­ç»ƒæ•°æ®è½¬æ¢ä¸ºé€‚åˆçš„æ•°æ®ç»“æ„ï¼Ÿ</br></br>
åœ¨è”é‚¦å­¦ä¹ ç¯å¢ƒä¸­ï¼ŒåŸå§‹æ•°æ®çš„æ ¼å¼å¯èƒ½å­˜åœ¨ä¸€äº›å·®å¼‚ï¼Œæ¯”å¦‚å›¾ç‰‡æ•°æ®å¯èƒ½ä½¿ç”¨äº†ä¸åŒçš„å°ºå¯¸æˆ–è€…æ ¼å¼ã€‚ä¸ºäº†å°½é‡æé«˜ç‰¹å¾è½¬æ¢çš„æ­£ç¡®ç‡ï¼Œä»£ç åº”å½“å°½é‡å…¼å®¹æ›´å¤šçš„å¯èƒ½æƒ…å†µã€‚
æˆ‘ä»¬æ¨èä½ åœ¨ä»»åŠ¡æè¿°ä¸­æ˜ç¡®æŒ‡å®šæ”¯æŒçš„æ•°æ®æ ¼å¼ï¼Œä»¥å¸®åŠ©æ•°æ®æ‹¥æœ‰è€…æ˜ç¡®å¦‚ä½•å¯¹æ•°æ®åšé¢„å¤„ç†ã€‚å¦‚æœå¯èƒ½çš„è¯ï¼Œä¹Ÿå¯ä»¥é™„å¸¦ä¸€äº›æ•°æ®å¤„ç†çš„æŒ‡å¯¼ã€‚

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªéªŒè¯è®¿é—®å’Œè½¬æ¢æ•°æ®çš„æ¨¡æ¿ï¼Œä½ å¯ä»¥åœ¨è¿™ä¸ªæ¨¡æ¿çš„åŸºç¡€ä¸Šä¿®æ”¹ï¼Œä»¥é€‚åº”ä½ çš„ä»»åŠ¡éœ€è¦ã€‚

```python
import logging
import os

import torchvision
from torch.utils.data import DataLoader

_logger = logging.getLogger("app")


class DatasetVerify(object):

    def __init__(self, task_id, current_node):
        self.task_id = task_id
        self.current_node = current_node

    def run(self) -> bool:
        """æ•°æ®é›†çš„æ ¡éªŒå…·ä½“é€»è¾‘."""
        _logger.info(f"start dataset verification for task {self.task_id} on {self.current_node}")
        root_dir = '/data/alphamed-federated-dataset/tutorials/MNIST/raw'
        return self._touch_data(root_dir) and self._load_data(root_dir)

    def _touch_data(self, root_dir: str) -> bool:
        file_list = [
            't10k-images-idx3-ubyte',
            't10k-images-idx3-ubyte.gz',
            't10k-labels-idx1-ubyte',
            't10k-labels-idx1-ubyte.gz',
            'train-images-idx3-ubyte',
            'train-images-idx3-ubyte.gz',
            'train-labels-idx1-ubyte',
            'train-labels-idx1-ubyte.gz'
        ]
        full_paths = [os.path.join(root_dir, _file) for _file in file_list]
        return all(os.path.exists(_file) and os.path.isfile(_file)
                    for _file in full_paths)

    def _load_data(self, root_dir: str) -> bool:
        data_loader = DataLoader(
            torchvision.datasets.MNIST(
                root_dir,
                train=True,
                download=False,
                transform=torchvision.transforms.Compose([
                    torchvision.transforms.ToTensor(),
                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
                ])
            )
        )
        return data_loader is not None and len(data_loader) > 0
```

python æ–‡ä»¶ä¸­å®šä¹‰çš„ç±»åå¿…é¡»æ˜¯ â€œDatasetVerifyâ€ã€‚å…¶ä¸­çš„ â€œ\_\_init__â€ åˆå§‹åŒ–æ–¹æ³•çš„å‚æ•°åˆ—è¡¨ä¸å¯ä»¥ä¿®æ”¹ï¼Œå¦åˆ™ä¼šå¯¼è‡´ä»£ç åŠ è½½å¤±è´¥ã€‚â€œrunâ€ æ–¹æ³•ä¸­çš„é€»è¾‘ç”¨äºæ£€æŸ¥æ˜¯å¦èƒ½å¤Ÿè®¿é—®åˆ°æ•°æ®ä»¥åŠèƒ½å¤Ÿæ­£ç¡®çš„å°†æ•°æ®è½¬åŒ–ä¸ºç‰¹å¾ï¼Œä½ å¯ä»¥æ ¹æ®ä»»åŠ¡éœ€è¦ç¼–å†™è‡ªå·±çš„æ£€æŸ¥é€»è¾‘ã€‚

å®é™…ä¸Šï¼Œä¸¤æ­¥æ£€æŸ¥éƒ½ä¸æ˜¯å¿…é¡»çš„ï¼Œä»¥æä¾›æœ€å¤§çš„çµæ´»æ€§ã€‚ä½†æ˜¯æˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½ å°½å¯èƒ½å®ç°å®ƒä»¬ã€‚å¦åˆ™å¯èƒ½å¯¼è‡´è¿è¡Œæ—¶é”™è¯¯ï¼Œå±Šæ—¶è°ƒè¯•çš„ä»£ä»·å¯èƒ½ä¼šé«˜å‡ºå¾ˆå¤šã€‚

## åˆ›å»ºä»»åŠ¡

ç™»å½• [AlphaMed ç®¡ç†é¡µé¢](http://81.70.132.120/)ã€‚æ–°å»ºä¸€ä¸ªè®¡ç®—ä»»åŠ¡ï¼Œåœ¨â€œè”é‚¦ç±»å‹â€é€‰é¡¹ä¸­é€‰æ‹©â€œæ¨ªå‘â€ï¼Œå¹¶æ ¹æ®éœ€è¦å¡«å†™å…¶å®ƒä»»åŠ¡ä¿¡æ¯ï¼Œç„¶åç‚¹å‡»â€œåˆ›å»ºä»»åŠ¡â€ã€‚

åˆ›å»ºä»»åŠ¡æ—¶éœ€è¦ä¸Šä¼ æˆ‘ä»¬åœ¨â€œæ£€æŸ¥æ•°æ®â€ç« èŠ‚ç¼–å†™çš„ python ä»£ç æ–‡ä»¶ï¼Œä»»åŠ¡ç®¡ç†å™¨å°†ä½¿ç”¨è¿™äº›é€»è¾‘æ£€æŸ¥æ¯ä¸€ä¸ªå‚ä¸è®¡ç®—çš„æ•°æ®èŠ‚ç‚¹ï¼Œä»¥ç¡®ä¿è®¡ç®—ä»»åŠ¡å¯åŠ¨åæ•°æ®å¯ç”¨ã€‚

## å®šä¹‰ä»»åŠ¡ç»†èŠ‚

ç°åœ¨ï¼Œå¯ä»¥å®šä¹‰æˆ‘ä»¬çš„è®¡ç®—ä»»åŠ¡ç»†èŠ‚äº†ã€‚æˆ‘ä»¬å‡å®šä½ å·²ç»ç†Ÿæ‚‰äº†æ·±åº¦å­¦ä¹ çš„ç›¸å…³çŸ¥è¯†ï¼Œå¹¶ä¸”å…·å¤‡äº†åˆ©ç”¨ PyTorch æ¡†æ¶å°†æ¨¡å‹æ¦‚å¿µè½¬åŒ–ä¸ºä»£ç çš„èƒ½åŠ›ã€‚è‹¥éå¦‚æ­¤ï¼Œå»ºè®®ä½ å…ˆå»å­¦ä¹ ä¸€ä¸‹è¿™äº›çŸ¥è¯†ï¼Œç„¶åå†å›æ¥ç»§ç»­åé¢çš„æ—…ç¨‹ã€‚

è¦å®šä¹‰ä¸€ä¸ª FedAvg è”é‚¦å­¦ä¹ ä»»åŠ¡ï¼Œä½ éœ€è¦å®šä¹‰ä¸€ä¸ª â€œFedAvgSchedulerâ€ çš„å­ç±»ï¼Œå¹¶å®ç°å…¶ä¸­çš„ä¸€äº›æ–¹æ³•ã€‚ä½ å¯ä»¥åœ¨æˆ‘ä»¬çš„ Notebook ç¼–è¾‘æ¡†ä¸­åˆ›å»ºä½ çš„ç¬¬ä¸€ä¸ª FedAvg è”é‚¦å­¦ä¹ ä»»åŠ¡ï¼Œå°±åƒè¿™æ ·ï¼š

```python
import os
from typing import Any, Dict

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torch.utils.data import DataLoader

from alphafed import logger
from alphafed.fed_avg import FedAvgScheduler

class DemoScheduler(FedAvgScheduler):
    ...
```

FedAvgScheduler æ¥æ”¶ä¸€äº›åˆå§‹åŒ–å‚æ•°ï¼Œä¸€äº›ä¸»è¦çš„å‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š
- min_clientsï¼ˆå¿…å¡«å‚æ•°ï¼‰ï¼šæ¯è½®è®­ç»ƒä¸­æœ€å°‘åŒ…å«çš„æ•°æ®å‚ä¸æ–¹æ•°é‡ï¼Œæ•°é‡ä¸è¶³ä¼šå¯¼è‡´è®­ç»ƒå¤±è´¥ï¼›
- max_clientsï¼ˆå¿…å¡«å‚æ•°ï¼‰ï¼šæ¯è½®è®­ç»ƒä¸­æœ€å¤šåŒ…å«çš„æ•°æ®å‚ä¸æ–¹æ•°é‡ï¼Œè¶…å‡ºæ—¶ä¼šå°†å¤šä½™çš„æ•°æ®å‚ä¸æ–¹æ’é™¤ï¼›
- max_roundsï¼ˆå¿…å¡«å‚æ•°ï¼‰ï¼šæœ€å¤šè®­ç»ƒè½®æ¬¡ï¼Œè¾¾åˆ°æ­¤è®­ç»ƒè½®æ¬¡åä»»åŠ¡ç»“æŸï¼›
- nameï¼ˆå¯é€‰å‚æ•°ï¼‰ï¼šè®­ç»ƒä»»åŠ¡çš„åç§°ï¼Œé»˜è®¤ä¸ºä»»åŠ¡ IDï¼›
- merge_epochsï¼ˆå¯é€‰å‚æ•°ï¼‰ï¼šæ¯ä¸€è½®èšåˆå‚æ•°ä¹‹å‰ï¼Œåœ¨æœ¬åœ°æ‰§è¡Œå¤šå°‘ä¸ªè®­ç»ƒè½®æ¬¡ï¼Œé»˜è®¤ä¸º 1ï¼›
- calculation_timeoutï¼ˆå¯é€‰å‚æ•°ï¼‰ï¼šè®¡ç®—è¶…æ—¶æ—¶é—´ï¼Œå¼€å§‹æ‰§è¡Œæœ¬åœ°è®­ç»ƒåï¼Œåœ¨æ­¤æ—¶é—´å†…æ²¡æœ‰æäº¤å‚æ•°æ›´æ–°ç»“æœå°†è¢«è§†ä¸ºè¶…æ—¶ï¼›
- log_roundsï¼ˆå¯é€‰å‚æ•°ï¼‰ï¼šæ¯éš”å‡ è½®è®­ç»ƒåï¼Œæ‰§è¡Œä¸€æ¬¡æµ‹è¯•å¹¶è®°å½•å½“å‰æ¨¡å‹æµ‹è¯•ç»“æœï¼›
 
æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥å®Œæˆå®ƒã€‚

### å®šä¹‰æ¨¡å‹

ç¬¬ä¸€ä¸ªä»»åŠ¡æ˜¯å®ç° â€œmake\_modelâ€ æ–¹æ³•ï¼Œå®ƒå°†è¿”å›ä»»åŠ¡è®¡ç®—æ—¶ä½¿ç”¨çš„æ¨¡å‹å¯¹è±¡ã€‚å¹¸è¿çš„æ˜¯ï¼Œè¿™å°±æ˜¯ä¸ªæ™®é€šçš„ torch.nn.Module å¯¹è±¡ã€‚

```python
class ConvNet(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(in_features=320, out_features=50)
        self.fc2 = nn.Linear(in_features=50, out_features=10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=-1)
```

```python
def build_model(self) -> nn.Module:
    model = ConvNet()
    return model
```

ç„¶åï¼Œæˆ‘ä»¬æ¥ä¸ºæ¨¡å‹æ­é…ä¸€ä¸ªä¼˜åŒ–å™¨ï¼Œå¸®åŠ©æˆ‘ä»¬è‡ªåŠ¨å¤„ç†æ¢¯åº¦ä¼˜åŒ–ã€‚

```python
def build_optimizer(self, model: nn.Module) -> optim.Optimizer:
    return optim.SGD(model.parameters(),
                     lr=self.learning_rate,
                     momentum=self.momentum)
```

æ¥å£å‚æ•°ä¼ å…¥çš„ model å¯¹è±¡ï¼Œå¹³å°ä¼šè‡ªåŠ¨ä¼ å…¥æ¥ä¸‹æ¥è®­ç»ƒçš„è¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ¨¡å‹å¯¹è±¡ï¼Œå› æ­¤å¯ä»¥ç›´æ¥ä½¿ç”¨ã€‚ä»”ç»†åˆ†æä»£ç ä¼šå‘ç°ï¼Œå…¶ä¸­ä½¿ç”¨äº†ä¸¤ä¸ªè¿˜æœªå®šä¹‰çš„å¯¹è±¡å±æ€§ï¼šâ€œself.learning\_rateâ€ï¼Œâ€œself.momentumâ€ã€‚è¿™ä¸¤ä¸ªå±æ€§æ˜¯åœ¨åˆå§‹åŒ–å¯¹è±¡çš„æ—¶å€™è¢«èµ‹å€¼çš„ï¼ŒæŒ‚åœ¨ â€œselfâ€ ä¸Šçš„å¥½å¤„æ˜¯ï¼Œå½“æˆ‘ä»¬åœ¨å…¶å®ƒæ–¹æ³•ä¸­éœ€è¦è®¿é—®å®ƒä»¬çš„æ—¶å€™ï¼Œå®ƒä»¬éšæ—¶éƒ½åœ¨ã€‚åé¢æˆ‘ä»¬ä¼šè¯¦ç»†ä»‹ç»ï¼Œç›®å‰å¯ä»¥æš‚æ—¶å¿½ç•¥è¿™ä¸ªé—®é¢˜ã€‚å½“ç„¶ä½ ä¹Ÿå¯ä»¥åœ¨ â€œmake\_modelâ€ï¼Œâ€œmake\_optimizerâ€ æ–¹æ³•ä¸­ç›´æ¥å®šä¹‰éœ€è¦çš„ä»»ä½•å˜é‡ã€‚

### åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨

ç¬¬äºŒä¸ªä»»åŠ¡æ˜¯å¤„ç†æ•°æ®çš„åŠ è½½ï¼Œéœ€è¦å®ç° â€œmake\_train\_dataloaderâ€ å’Œ â€œmake\_test\_dataloaderâ€ ä¸¤ä¸ªæ–¹æ³•ï¼Œå®ƒä»¬å°†åˆ†åˆ«è¿”å›è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®çš„æ•°æ®åŠ è½½å™¨å¯¹è±¡ã€‚åŒæ ·çš„ï¼Œè¿™ä¸¤ä¸ªå¯¹è±¡éƒ½æ˜¯æ™®é€šçš„ torch.utils.data.DataLoader å¯¹è±¡ï¼Œæˆ‘ä»¬åº”è¯¥å¯¹æ­¤å¾ˆç†Ÿæ‚‰äº†ã€‚

```python
def build_train_dataloader(self) -> DataLoader:
    return DataLoader(
        torchvision.datasets.MNIST(
            '/data/alphamed-federated-dataset/tutorials/',
            train=True,
            download=True,
            transform=torchvision.transforms.Compose([
                torchvision.transforms.ToTensor(),
                torchvision.transforms.Normalize((0.1307,), (0.3081,))
            ])
        ),
        batch_size=self.batch_size,
        shuffle=True
    )

def build_test_dataloader(self) -> DataLoader:
    return DataLoader(
        torchvision.datasets.MNIST(
            '/data/alphamed-federated-dataset/tutorials/',
            train=False,
            download=True,
            transform=torchvision.transforms.Compose([
                torchvision.transforms.ToTensor(),
                torchvision.transforms.Normalize((0.1307,), (0.3081,))
            ])
        ),
        batch_size=self.batch_size,
        shuffle=False
    )
```

### è·å–å’ŒåŠ è½½å‚æ•°

æˆ‘ä»¬çš„è®¡ç®—ç›®æ ‡æ˜¯æ›´æ–°æ¨¡å‹çš„ç›¸å…³å‚æ•°ï¼Œæ‰€ä»¥æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å®ç° â€œstate\_dictâ€ å’Œ â€œload\_state\_dictâ€ æ–¹æ³•ï¼Œå®ƒä»¬åˆ†åˆ«ç”¨æ¥è·å–å’ŒåŠ è½½éœ€è¦æ›´æ–°çš„å‚æ•°ã€‚è¿™ä¸¤ä¸ªæ–¹æ³•éœ€è¦é…åˆå·¥ä½œï¼Œäº’ç›¸å¯ä»¥è§†ä¸ºå¯¹æ–¹çš„é•œåƒã€‚

```python
def state_dict(self) -> Dict[str, torch.Tensor]:
    return self.model.state_dict()

def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
    self.model.load_state_dict(state_dict)
```

å½“ç„¶ä½ ä¹Ÿå¯ä»¥åœ¨ â€œstate\_dictâ€ æ–¹æ³•ä¸­è¿”å›å…¶å®ƒéœ€è¦å­¦ä¹ çš„å‚æ•°ï¼Œæ¯”å¦‚ä¼˜åŒ–å™¨çš„å‚æ•°ï¼Œå¹¶åœ¨ â€œload\_state\_dictâ€ æ–¹æ³•ä¸­å°†å®ƒä»¬é‡æ–°åŠ è½½åˆ°ä¼˜åŒ–å™¨ä¸­ã€‚â€œstate\_dictâ€ è¿”å›çš„æ‰€æœ‰å‚æ•°éƒ½éµå¾ª FedAvg ç®—æ³•çš„å‚æ•°å¤„ç†æµç¨‹è¿›è¡Œè®¡ç®—å’Œæ›´æ–°ï¼Œå› æ­¤è¯·ç¡®ä¿åªè¿”å›å…¼å®¹çš„å‚æ•°ç±»å‹ã€‚å¦‚æœè¿”å›äº†å¦‚ torch.bool ç±»å‹çš„å‚æ•°ï¼Œå…¶æ›´æ–°åçš„å€¼å¯èƒ½ä¸ç¬¦åˆä½ çš„é¢„æœŸï¼Œç”šè‡³å¯èƒ½å¼•èµ·ç¨‹åºé”™è¯¯ã€‚

### å®šä¹‰è®­ç»ƒé€»è¾‘

ç°åœ¨ï¼Œå¯ä»¥å®šä¹‰æˆ‘ä»¬çš„è®­ç»ƒè¿‡ç¨‹äº†ã€‚å¥½æ¶ˆæ¯æ˜¯ï¼Œä¸åœ¨æœ¬åœ°æ‰§è¡Œè®­ç»ƒçš„æ–¹å¼ä¸€æ¨¡ä¸€æ ·ã€‚

```python
def train_an_epoch(self) -> None:
    self.model.train()
    for data, labels in self.train_loader:
        data: torch.Tensor
        labels: torch.Tensor
        data, labels = data.to(self.device), labels.to(self.device)
        self.optimizer.zero_grad()
        output = self.model(data)
        loss = F.nll_loss(output, labels)
        loss.backward()
        self.optimizer.step()
```

### å®šä¹‰æµ‹è¯•é€»è¾‘

ä¸ºäº†éªŒè¯æ¨¡å‹çš„è®­ç»ƒæˆæœï¼Œæˆ‘ä»¬éœ€è¦åœ¨å¿…è¦çš„æ—¶å€™å¯¹å½“å‰çš„æœ€æ–°å‚æ•°åšä¸€äº›æµ‹è¯•ã€‚åŒæ ·çš„ï¼Œæµ‹è¯•çš„æ–¹å¼ä¸æœ¬åœ°æµ‹è¯•ä¹Ÿæ˜¯ä¸€æ¨¡ä¸€æ ·çš„ã€‚
å¦‚æœéœ€è¦åœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­è®°å½•ä¸€äº›è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥ä¾¿è®­ç»ƒå®Œæˆä¹‹ååšä¸€äº›åˆ†æï¼Œå¯ä»¥é€šè¿‡ä¸º test æ–¹æ³•æ·»åŠ  register\_metrics æ³¨è§£çš„æ–¹å¼æ³¨å†ŒæŒ‡æ ‡åˆ—è¡¨ï¼Œå¹¶åœ¨æ–¹æ³•ä¸­çš„ä»»ä½•åœ°æ–¹é€šè¿‡ append\_metrics\_item æ–¹æ³•æ·»åŠ æŒ‡æ ‡è®°å½•ä¿¡æ¯ã€‚æ¯”å¦‚ï¼š

```python
@register_metrics(name='test_results', keys=['average_loss', 'accuracy', 'correct_rate'])
def test(self):
    ...
```

ä¸º test æ–¹æ³•æ·»åŠ äº†ä¸€ä¸ªåä¸º test\_results çš„æŒ‡æ ‡é›†åˆï¼Œå…¶ä¸­åŒ…æ‹¬äº† average\_loss, accuracy, correct\_rate ä¸‰ä¸ªæŒ‡æ ‡é¡¹ç›®ã€‚å½“éœ€è¦å¬å› test\_results æŒ‡æ ‡é›†åˆçš„æ—¶å€™ï¼Œå¯ä»¥é€šè¿‡ self.get\_metrics('test\_results') è·å–è¯¥æŒ‡æ ‡é›†åˆå¯¹è±¡ã€‚ä¸‹é¢çš„ä»£ç ç¤ºä¾‹å…ˆè·å–åˆ°äº† test\_results æŒ‡æ ‡é›†åˆï¼Œç„¶åå‘å…¶ä¸­æ·»åŠ äº†ä¸€æ¡æµ‹è¯•è®°å½•ã€‚åœ¨è¿™æ¬¡æµ‹è¯•ä¸­ï¼Œaverage\_loss çš„å€¼ä¸º 1.0ï¼Œaccuracy çš„å€¼ä¸º 0.801ï¼Œcorrect\_rate çš„å€¼ä¸º 80.1ã€‚

```python
self.get_metrics('test_results').append_metrics_item({
    'average_loss': 1.0,
    'accuracy': 0.801,
    'correct_rate': 80.1
})
```

å¯ä»¥ä¸º test æ–¹æ³•æ³¨å†Œä»»æ„æ•°é‡çš„æŒ‡æ ‡é›†åˆï¼Œåªéœ€è¦ä¾æ¬¡æ·»åŠ  register\_metrics æ³¨è§£å³å¯ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­æ¯æ¬¡æ‰§è¡Œ test æ–¹æ³•çš„æ—¶å€™ï¼Œè®¡ç®—å‡ºéœ€è¦è®°å½•çš„æŒ‡æ ‡ï¼Œå°†ä»–ä»¬çš„å€¼ä½œä¸ºä¸€æ¡æ–°çš„è®°å½•åŠ å…¥é›†åˆï¼Œå³å¯è¿½è¸ªè®­ç»ƒè¿‡ç¨‹ä¸­æ„Ÿå…´è¶£çš„çŠ¶æ€å’Œæ•°å€¼ã€‚å½“è®­ç»ƒå®Œæˆåï¼Œæ¯ä¸€ä¸ªæŒ‡æ ‡é›†åˆä¼šè‡ªåŠ¨ç”Ÿæˆä¸€ä¸ª CSV è¡¨æ ¼æ–‡ä»¶ï¼ŒåŒ…å«è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ‰€æœ‰è®°å½•ï¼Œä»¥ä¾›ä¸‹è½½åè¿›ä¸€æ­¥åˆ†æã€‚

```python
@register_metrics(name='timer', keys=['run_time'])
@register_metrics(name='test_results', keys=['average_loss', 'accuracy', 'correct_rate'])
def test(self):
    start = time()
    self.model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, labels in self.test_loader:
            data: torch.Tensor
            labels: torch.Tensor
            data, labels = data.to(self.device), labels.to(self.device)
            output: torch.Tensor = self.model(data)
            test_loss += F.nll_loss(output, labels, reduction='sum').item()
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(labels.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)
    accuracy = correct / len(test_loader.dataset)
    correct_rate = 100. * accuracy
    logger.info(f'Test set: Average loss: {test_loss:.4f}')
    logger.info(
        f'Test set: Accuracy: {accuracy} ({correct_rate:.2f}%)'
    )

    end = time()
    self.get_metrics('timer').append_metrics_item({'run_time': end - start})
    self.get_metrics('test_results').append_metrics_item({
        'average_loss': test_loss,
        'accuracy': accuracy,
        'correct_rate': correct_rate
    })
```

å¥½äº†ï¼Œåˆ°æ­¤ä¸ºæ­¢ï¼Œæ‰€æœ‰å¿…é¡»çš„å·¥ä½œéƒ½å·²ç»åšå®Œäº†ã€‚ä¸‹é¢çš„æ­¥éª¤æ˜¯å¯é€‰çš„ï¼Œä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€è¦é€‰æ‹©å®ç°ã€‚å½“ç„¶ï¼Œä¹Ÿå¯ä»¥å…¨éƒ¨è·³è¿‡ã€‚

## å®šä¹‰å¯é€‰çš„ä»»åŠ¡ç»†èŠ‚

### æ·»åŠ è‡ªå·±çš„åˆå§‹åŒ–é…ç½®

åœ¨å¤§å¤šæ•°ç°å®åœºæ™¯ä¸­ï¼Œé»˜è®¤çš„åˆå§‹åŒ–é…ç½®é¡¹å¯èƒ½éƒ½ä¸è¶³ä»¥æ»¡è¶³ä½ çš„å…¨éƒ¨éœ€æ±‚ã€‚ä¾æ®ä½ ä½¿ç”¨çš„æ¨¡å‹å’Œè®­ç»ƒæ–¹æ³•ï¼Œä½ å¯èƒ½éœ€è¦åŠ å…¥æ›´å¤šçš„å‚æ•°ä»¥è·å¾—æ›´å¥½çš„è®­ç»ƒæ•ˆæœã€‚è¦å®ç°è¿™ä¸€ç‚¹å¾ˆç®€å•ï¼Œå°±åƒæ‰€æœ‰æ™®é€šçš„ python ç±»å®šä¹‰ä¸€æ ·ï¼Œä½ åªéœ€è¦åœ¨ â€œ\_\_init__â€ æ–¹æ³•ä¸­åšä¸€äº›å¿…è¦çš„å¤„ç†ã€‚

```python
def __init__(self,
             min_clients: int,
             max_clients: int,
             name: str = None,
             max_rounds: int = 0,
             merge_epoch: int = 1,
             calculation_timeout: int = 300,
             log_rounds: int = 0,
             is_centralized: bool = True,
             batch_size: int = 64,
             learning_rate: float = 0.01,
             momentum: float = 0.5) -> None:
    super().__init__(min_clients=min_clients,
                     max_clients=max_clients,
                     name=name,
                     max_rounds=max_rounds,
                     merge_epochs=merge_epoch,
                     calculation_timeout=calculation_timeout,
                     log_rounds=log_rounds,
                     is_centralized=is_centralized)
    self.batch_size = batch_size
    self.learning_rate = learning_rate
    self.momentum = momentum

    self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    self.seed = 42
    torch.manual_seed(self.seed)
```

è¿˜è®°å¾—æˆ‘ä»¬ä¹‹å‰é‡åˆ°çš„ â€œself.learning\_rateâ€ã€â€œself.momentumâ€ å‚æ•°å—ï¼Ÿç°åœ¨ä½ çŸ¥é“å®ƒä»¬æ˜¯æ€ä¹ˆæ¥çš„äº†å§ã€‚åœ¨ç°å®åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦æ·»åŠ å¤šä¸ªæœ‰åŠ©äºæ¨¡å‹è®­ç»ƒçš„å‚æ•°ã€‚ä¹Ÿè®¸å…¶ä¸­æœ‰ä¸€äº›æ˜¯éœ€è¦åœ¨å¤–éƒ¨æ§åˆ¶çš„ï¼Œæ¯”å¦‚ â€œbatch\_sizeâ€ã€â€œlearning\_rateâ€ã€â€œmomentumâ€ï¼Œä½ å¯ä»¥æŠŠå®ƒä»¬åŠ å…¥åˆå§‹åŒ–çš„å‚æ•°åˆ—è¡¨ä¸­ã€‚ä¹Ÿè®¸è¿˜æœ‰ä¸€äº›å‚æ•°ä¸å¸Œæœ›å—åˆ°å¤–éƒ¨ç¯å¢ƒçš„å½±å“ï¼Œæ¯”å¦‚ â€œdeviceâ€ã€â€œseedâ€ï¼Œé‚£å°±æŠŠå®ƒä»¬è—åœ¨ â€œ\_\_init__â€ å†…éƒ¨å¥½äº†ã€‚è¿™æ ·å¯ä»¥é¿å…å¤–éƒ¨ä½¿ç”¨è€…é”™è¯¯çš„è®¾ç½®è¿™äº›å‚æ•°ï¼ŒåŒæ—¶è¿˜èƒ½ä¿è¯è®­ç»ƒè¿‡ç¨‹ä¸­éšæ—¶å¯ä»¥è®¿é—®åˆ°è¿™äº›å‚æ•°ã€‚

**è¯·è®°ä½ï¼Œæ‰€æœ‰è¿™äº›é™„åŠ çš„å‚æ•°ï¼Œéƒ½éœ€è¦ä½ è‡ªå·±æ¥ç®¡ç†ã€‚**

### éªŒè¯è¿è¡Œç¯å¢ƒ

åœ¨å®é™…è¿è¡Œä¹‹å‰ï¼Œå¯èƒ½ä¼šå¸Œæœ›å¯¹è¿è¡Œç¯å¢ƒå†åšä¸€äº›æ£€æŸ¥ï¼Œå¸®åŠ©å‘ç°ä¸€äº›æ½œåœ¨çš„é”™è¯¯ã€‚å¦‚æœä½ ç¡®å®æœ‰æ­¤éœ€æ±‚ï¼Œå¯ä»¥å®ç° â€œvalidate\_contextâ€ æ–¹æ³•ï¼Œæ·»åŠ ä»»ä½•ä½ éœ€è¦çš„æ£€æŸ¥é€»è¾‘ï¼Œæˆ–è€…è¾“å‡ºä¸€äº›ç¯å¢ƒä¿¡æ¯ä»¥åˆ©äºæ£€æŸ¥é—®é¢˜ã€‚ä½†æ˜¯éœ€è¦ç•™æ„ï¼Œ**ä¸è¦å¿˜è®°å…ˆè°ƒç”¨çˆ¶ç±»çš„æ–¹æ³•ï¼Œå¦åˆ™ä¼šå¯¼è‡´è¿è¡Œæ—¶é”™è¯¯ã€‚**

å¦‚æœä½ æ²¡æœ‰è¿™æ–¹é¢çš„éœ€æ±‚ï¼Œåˆ™å¯ä»¥ç›´æ¥è·³è¿‡è¿™ä¸€æ­¥ã€‚

```python
def validate_context(self):
    super().validate_context()
    assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
    logger.info(f'There are {len(self.train_loader.dataset)} samples for training.')
    assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
    logger.info(f'There are {len(self.test_loader.dataset)} samples for testing.')
```

### æ§åˆ¶ä»»åŠ¡å®Œæˆçš„æ¡ä»¶

é»˜è®¤æƒ…å†µä¸‹ï¼Œè®¡ç®—ä»»åŠ¡å°†åœ¨å®Œæˆ max\_rounds è½®çš„è®­ç»ƒä¹‹åè‡ªåŠ¨å®Œæˆã€‚åœ¨ä¸€äº›æ›´å¤æ‚çš„åœºæ™¯ä¸­ï¼Œä½ å¯èƒ½å¸Œæœ›ä½¿ç”¨ä¸€äº›æ›´å¤æ‚çš„é€»è¾‘ä»¥åˆ¤æ–­æ˜¯å¦è¦ç»“æŸè®­ç»ƒï¼Œç”šè‡³å¯èƒ½å¸Œæœ›è®­ç»ƒæ°¸è¿œæ‰§è¡Œä¸‹å»ã€‚æ­¤æ—¶å°±éœ€è¦ä¿®æ”¹ â€œis\_task\_finishedâ€ æ–¹æ³•çš„åˆ¤æ–­é€»è¾‘äº†ï¼Œå°†å®ƒä¿®æ”¹æˆä½ å¸Œæœ›çš„æ ·å­å§ã€‚

```python
def is_task_finished(self) -> bool:
    """By default true if reach the max rounds configured."""
    return self._is_reach_max_rounds()
```

# å¯åŠ¨ä»»åŠ¡

è‡³æ­¤ï¼Œæ‰€æœ‰ä½ éœ€è¦äº†è§£çš„çŸ¥è¯†éƒ½å·²ç»ä»‹ç»å®Œäº†ã€‚åœ¨çœŸæ­£å¯åŠ¨æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ªä»»åŠ¡ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆæŠŠå‰é¢é‚£äº›é›¶æ•£çš„æ–¹æ³•å®ç°æ•´ç†ä¸€ä¸‹ï¼Œæ±‡æ€»åˆ°ä¸€èµ·ã€‚ç„¶åï¼Œä½ è¿˜éœ€è¦åœ¨ä»»åŠ¡ç®¡ç†é¡µé¢ä¸­æŸ¥çœ‹ä¸€ä¸‹å½“å‰ä»»åŠ¡çš„ IDã€‚ä»»åŠ¡ ID å¯ä»¥åœ¨ Playgroud é¡µé¢æ‰¾åˆ°å¹¶å¤åˆ¶ï¼Œå¦‚ä¸‹å›¾ï¼š
![è·å–å½“å‰ä»»åŠ¡ ID](./task_id.png)

ç°åœ¨ï¼Œå‘å°„ä½ çš„ç¬¬ä¸€æš ğŸš€ å§ ...

```python
import os
from time import time
from typing import Dict

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torch import optim
from torch.utils.data import DataLoader

from alphafed import logger
from alphafed.fed_avg import FedAvgScheduler, register_metrics


class ConvNet(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(in_features=320, out_features=50)
        self.fc2 = nn.Linear(in_features=50, out_features=10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=-1)


class DemoFedAvg(FedAvgScheduler):

    def __init__(self,
                 min_clients: int,
                 max_clients: int,
                 name: str = None,
                 max_rounds: int = 0,
                 merge_epoch: int = 1,
                 calculation_timeout: int = 300,
                 log_rounds: int = 0,
                 is_centralized: bool = True,
                 batch_size: int = 64,
                 learning_rate: float = 0.01,
                 momentum: float = 0.5) -> None:
        super().__init__(min_clients=min_clients,
                         max_clients=max_clients,
                         name=name,
                         max_rounds=max_rounds,
                         merge_epochs=merge_epoch,
                         calculation_timeout=calculation_timeout,
                         log_rounds=log_rounds,
                         is_centralized=is_centralized)
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.momentum = momentum

        self._time_metrics = None

        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.seed = 42
        torch.manual_seed(self.seed)

    def build_model(self) -> nn.Module:
        model = ConvNet()
        return model

    def build_optimizer(self, model: nn.Module) -> optim.Optimizer:
        return optim.SGD(model.parameters(),
                         lr=self.learning_rate,
                         momentum=self.momentum)

    def build_train_dataloader(self) -> DataLoader:
        return DataLoader(
            torchvision.datasets.MNIST(
                '/data/alphamed-federated-dataset/tutorials/',
                train=True,
                download=True,
                transform=torchvision.transforms.Compose([
                    torchvision.transforms.ToTensor(),
                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
                ])
            ),
            batch_size=self.batch_size,
            shuffle=True
        )

    def build_test_dataloader(self) -> DataLoader:
        return DataLoader(
            torchvision.datasets.MNIST(
                '/data/alphamed-federated-dataset/tutorials/',
                train=False,
                download=True,
                transform=torchvision.transforms.Compose([
                    torchvision.transforms.ToTensor(),
                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
                ])
            ),
            batch_size=self.batch_size,
            shuffle=False
        )

    def state_dict(self) -> Dict[str, torch.Tensor]:
        return self.model.state_dict()

    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
        self.model.load_state_dict(state_dict)

    def validate_context(self):
        super().validate_context()
        assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
        logger.info(f'There are {len(self.train_loader.dataset)} samples for training.')
        assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
        logger.info(f'There are {len(self.test_loader.dataset)} samples for testing.')

    def train_an_epoch(self) -> None:
        self.model.train()
        for data, labels in self.train_loader:
            data: torch.Tensor
            labels: torch.Tensor
            data, labels = data.to(self.device), labels.to(self.device)
            self.optimizer.zero_grad()
            output = self.model(data)
            loss = F.nll_loss(output, labels)
            loss.backward()
            self.optimizer.step()

    @register_metrics(name='timer', keys=['run_time'])
    @register_metrics(name='test_results', keys=['average_loss', 'accuracy', 'correct_rate'])
    def test(self):
        start = time()
        self.model.eval()
        test_loss = 0
        correct = 0
        with torch.no_grad():
            for data, labels in self.test_loader:
                data: torch.Tensor
                labels: torch.Tensor
                data, labels = data.to(self.device), labels.to(self.device)
                output: torch.Tensor = self.model(data)
                test_loss += F.nll_loss(output, labels, reduction='sum').item()
                pred = output.max(1, keepdim=True)[1]
                correct += pred.eq(labels.view_as(pred)).sum().item()

        test_loss /= len(test_loader.dataset)
        accuracy = correct / len(test_loader.dataset)
        correct_rate = 100. * accuracy
        logger.info(f'Test set: Average loss: {test_loss:.4f}')
        logger.info(
            f'Test set: Accuracy: {accuracy} ({correct_rate:.2f}%)'
        )

        end = time()
        self.get_metrics('timer').append_metrics_item({'run_time': end - start})
        self.get_metrics('test_results').append_metrics_item({
            'average_loss': test_loss,
            'accuracy': accuracy,
            'correct_rate': correct_rate
        })


scheduler = DemoFedAvg(min_clients=2,
                       max_clients=3,
                       name='demo_fed_avg',
                       max_rounds=5,
                       merge_epochs=1,
                       log_rounds=1,
                       calculation_timeout=120)
scheduler.launch_task(task_id='YOUR_TASK_ID')
```

# åˆ›å»ºä¸€ä¸ª FedSGD è”é‚¦å­¦ä¹ ä»»åŠ¡

FedSGD å¯ä»¥è¢«è§†ä¸º FedAvg ç®—æ³•ä¸­çš„ä¸€ä¸ªç‰¹ä¾‹ã€‚ä¸€èˆ¬è€Œè¨€ï¼Œå®ƒçš„è®­ç»ƒé€Ÿåº¦å’Œæ•ˆæœå‡è½åäº FedAvgï¼Œå› æ­¤å¹¶ä¸é€‚åˆåº”ç”¨åœ¨å®é™…çš„ä¸šåŠ¡åœºæ™¯ä¸­ã€‚ä½†æ˜¯åœ¨ç ”ç©¶åœºæ™¯ä¸­å…¶ç»å¸¸è¢«ç”¨äºæä¾›ä¸€ä¸ªåŸºç¡€çš„ baselineï¼Œå› æ­¤æˆ‘ä»¬æä¾›äº†ä¸€ä¸ª FedSGD çš„åŸºç¡€ç±»ï¼Œä»¥æ–¹ä¾¿åœ¨ç ”ç©¶ä¸­ä½¿ç”¨ã€‚

æ—¢ç„¶ FedSGD ç®—æ³•æ˜¯ FedAvg ç®—æ³•ä¸­çš„ä¸€ä¸ªç‰¹ä¾‹ï¼Œå› æ­¤äºŒè€…çš„å¤§éƒ¨åˆ†å†…å®¹æ˜¯ç›¸åŒçš„ï¼Œæ‰€ä»¥è¿™é‡Œåªä»‹ç»äºŒè€…å­˜åœ¨å·®å¼‚çš„éƒ¨åˆ†ã€‚

### åˆå§‹åŒ–å‚æ•°

FedSGD ç®—æ³•è¦æ±‚åœ¨ä¸€è½®è¿­ä»£ä¸­ï¼Œå¿…é¡»åŒ…å«æ‰€æœ‰çš„å‚ä¸æ–¹ï¼Œå› æ­¤åˆå§‹åŒ–å‚æ•°ä¸­çš„ max\_clients å‚æ•°è¢«ç§»é™¤äº†ã€‚æ‰€æœ‰åœ¨çº¿çš„å‚ä¸æ–¹éƒ½ä¼šå‚ä¸æ¯ä¸€è½®çš„è¿ç®—ã€‚ä½† min\_clients å‚æ•°ä¾ç„¶æœ‰æ•ˆã€‚

FedSGD ç®—æ³•è¦æ±‚åœ¨æ¯ä¸€è½®è¿­ä»£ä¸­ï¼Œæœ¬åœ°è®­ç»ƒåªèƒ½æ‰§è¡Œä¸€ä¸ª epochï¼Œå› æ­¤ merge\_epochs å‚æ•°è¢«ç§»é™¤äº†ï¼Œå®ƒå°†æ°¸è¿œä¸º 1ã€‚

ä¸‹é¢çš„ä»£ç å±•ç¤ºäº†å¦‚ä½•å®šä¹‰ä¸€ä¸ª FedSGD ç®—æ³•çš„å®ç°ã€‚

```python
import os
from time import time
from typing import Dict

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torch import optim
from torch.utils.data import DataLoader

from alphafed import logger
from alphafed.fed_avg import FedSGDScheduler, register_metrics

class DemoFedSGD(FedSGDScheduler):
    ...


scheduler = DemoFedSGD(min_clients=3,
                       name='demo_fed_sgd',
                       max_rounds=50,
                       log_rounds=1,
                       calculation_timeout=60)
```

## æ§åˆ¶è®­ç»ƒé›†çš„ batch_size

FedSGD ç®—æ³•è¦æ±‚åœ¨ä¸€è½®è¿­ä»£ä¸­ï¼Œæ‰€æœ‰çš„è®­ç»ƒæ ·æœ¬åº”å½“è¢«æ”¾ç½®åœ¨ä¸€ä¸ªæ‰¹æ¬¡ä¸­ã€‚å› æ­¤åœ¨æä¾›è®­ç»ƒæ•°æ®åŠ è½½å™¨æ—¶ï¼Œè¦å°†å…¶ batch_size è®¾ç½®ä¸ºè®­ç»ƒé›†æ ·æœ¬æ€»æ•°é‡ã€‚æ¡†æ¶ä¼šå¯¹æ­¤è¿›è¡Œæ£€æŸ¥ï¼Œå¦‚æœå‘ç°ä¸ç¬¦åˆå°†ä¼šå¯¼è‡´è®­ç»ƒå¯åŠ¨å¤±è´¥ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š

```python
def build_train_dataloader(self) -> DataLoader:
    dataset = torchvision.datasets.MNIST(
        os.path.join('root_path', 'data'),
        train=True,
        download=True,
        transform=torchvision.transforms.Compose([
            torchvision.transforms.ToTensor(),
            torchvision.transforms.Normalize((0.1307,), (0.3081,))
        ])
    )
    return DataLoader(dataset=dataset, batch_size=len(dataset), shuffle=True)
```

FedSGD ç®—æ³•å…¶ä½™éƒ¨åˆ†çš„å®ç°æ–¹å¼å’Œè¦æ±‚ä¸ FedAvg ç®—æ³•å®Œå…¨ä¸€è‡´ï¼Œè¯·å‚è€ƒ FedAvg ç®—æ³•éƒ¨åˆ†çš„è¯´æ˜ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªå®Œæ•´çš„ FedSGD ç®—æ³•ç¤ºä¾‹ï¼š

```python
import os
from typing import Dict

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torch.utils.data import DataLoader

from alphafed import logger
from alphafed.fed_avg import FedSGDScheduler


class ConvNet(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(in_features=320, out_features=50)
        self.fc2 = nn.Linear(in_features=50, out_features=10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=-1)


class DemoFedSGD(FedSGDScheduler):

    def __init__(self,
                 min_clients: int,
                 name: str = None,
                 max_rounds: int = 0,
                 calculation_timeout: int = 300,
                 log_rounds: int = 0,
                 is_centralized: bool = True,
                 batch_size: int = 64,
                 learning_rate: float = 0.01,
                 momentum: float = 0.5) -> None:
        super().__init__(min_clients=min_clients,
                         name=name,
                         max_rounds=max_rounds,
                         calculation_timeout=calculation_timeout,
                         log_rounds=log_rounds,
                         is_centralized=is_centralized)
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.momentum = momentum

        self._time_metrics = None

        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.seed = 42
        torch.manual_seed(self.seed)

    def build_model(self) -> nn.Module:
        model = ConvNet()
        return model

    def build_optimizer(self, model: nn.Module) -> optim.Optimizer:
        return optim.SGD(model.parameters(),
                         lr=self.learning_rate,
                         momentum=self.momentum)

    def build_train_dataloader(self) -> DataLoader:
        dataset = torchvision.datasets.MNIST(
            os.path.join(self.name, 'data'),
            train=True,
            download=True,
            transform=torchvision.transforms.Compose([
                torchvision.transforms.ToTensor(),
                torchvision.transforms.Normalize((0.1307,), (0.3081,))
            ])
        )
        return DataLoader(dataset=dataset, batch_size=len(dataset), shuffle=True)

    def build_test_dataloader(self) -> DataLoader:
        return DataLoader(
            torchvision.datasets.MNIST(
                os.path.join(self.name, 'data'),
                train=False,
                download=True,
                transform=torchvision.transforms.Compose([
                    torchvision.transforms.ToTensor(),
                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
                ])
            ),
            batch_size=self.batch_size,
            shuffle=False
        )

    def state_dict(self) -> Dict[str, torch.Tensor]:
        return self.model.state_dict()

    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
        self.model.load_state_dict(state_dict)

    def validate_context(self):
        super().validate_context()
        assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
        logger.info(f'There are {len(self.train_loader.dataset)} samples for training.')
        assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
        logger.info(f'There are {len(self.test_loader.dataset)} samples for testing.')

    def train_an_epoch(self) -> None:
        self.model.train()
        for data, labels in self.train_loader:
            data: torch.Tensor
            labels: torch.Tensor
            data, labels = data.to(self.device), labels.to(self.device)
            self.optimizer.zero_grad()
            output = self.model(data)
            loss = F.nll_loss(output, labels)
            loss.backward()
            self.optimizer.step()

    @register_metrics(name='timer', keys=['run_time'])
    @register_metrics(name='test_results', keys=['average_loss', 'accuracy', 'correct_rate'])
    def test(self):
        start = time()
        self.model.eval()
        test_loss = 0
        correct = 0
        with torch.no_grad():
            for data, labels in self.test_loader:
                data: torch.Tensor
                labels: torch.Tensor
                data, labels = data.to(self.device), labels.to(self.device)
                output: torch.Tensor = self.model(data)
                test_loss += F.nll_loss(output, labels, reduction='sum').item()
                pred = output.max(1, keepdim=True)[1]
                correct += pred.eq(labels.view_as(pred)).sum().item()

        test_loss /= len(test_loader.dataset)
        accuracy = correct / len(test_loader.dataset)
        correct_rate = 100. * accuracy
        logger.info(f'Test set: Average loss: {test_loss:.4f}')
        logger.info(
            f'Test set: Accuracy: {accuracy} ({correct_rate:.2f}%)'
        )

        end = time()
        self.get_metrics('timer').append_metrics_item({'run_time': end - start})
        self.get_metrics('test_results').append_metrics_item({
            'average_loss': test_loss,
            'accuracy': accuracy,
            'correct_rate': correct_rate
        })


scheduler = DemoFedSGD(min_clients=2,
                       name='demo_fed_sgd',
                       max_rounds=5,
                       log_rounds=1,
                       calculation_timeout=120)
scheduler.launch_task(task_id='YOUR_TASK_ID')
```
