{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义联邦学习算法\n",
    "\n",
    "AlphaMed 平台内置了一些常用的算法调度器实现。然而现实世界的需求千变万化，内置实现并不总能满足现实任务的需要。为此 AlphaMed 平台提供了对自定义联邦算法的支持。参考以下介绍的流程，工程师可以根据自己的业务需要定制各种联邦学习算法。\n",
    "\n",
    "**以下说明仅限于算法计算流程，不涉及计算开始之前的数据验证操作。**\n",
    "\n",
    "在 AlphaMed 平台自定义联邦学习算法并实现算法对应的调度器主要有以下几个步骤：\n",
    "1. 定义联邦学习算法流程；\n",
    "2. 根据算法流程，定义调度流程和各个参与角色的流程；\n",
    "3. 根据调度流程，定义用于互相协调的消息；\n",
    "4. 依据第 3 步定义的合约消息，实现对应的合约消息体、消息工厂、消息发生工具；（关于自定义合约消息的内容看[这里](6.%20%E5%90%88%E7%BA%A6%E6%B6%88%E6%81%AF%E6%9C%BA%E5%88%B6%E7%AE%80%E4%BB%8B.ipynb)）\n",
    "5. 设计流程中需要用户实现的接口；\n",
    "6. 实现流程调度代码逻辑。\n",
    "\n",
    "下面按照上述步骤逐个演示。\n",
    "\n",
    "## 定义联邦学习算法流程\n",
    "\n",
    "这里定义一个极简版的 FedAvg 流程，仅提供按照设置的轮次训练和聚合的功能，重启恢复、异常处理、安全隐私等其它功能均不考虑。但已经足够演示如何设计一个算法并将其在 AlphaMed 平台上实现。定义算法流程时先不考虑实际运行时的外部约束，比如节点集合同步、AlphaMed 平台要求等，以避免处理逻辑过于复杂，影响了对核心流程的理解。\n",
    "\n",
    "算法流程如下：\n",
    "```\n",
    "聚合方初始化全局模型、参与方初始化本地模型；  \n",
    "for 设置的训练轮次：  \n",
    "    聚合方向所有参与方发送全局模型；  \n",
    "    参与方接收全局模型，使用其更新本地模型；  \n",
    "    参与方在本地做一个 epoch 的训练，更新本地模型；  \n",
    "    参与方将本地模型发送给聚合方；  \n",
    "    聚合方平均所有参与方的本地模型，得到新的全局模型；  \n",
    "    聚合方使用测试数据做一次测试，得到全局模型的评估指标数据；\n",
    "```\n",
    "\n",
    "## 根据算法流程，定义调度流程和各个参与角色的流程\n",
    "\n",
    "定义调度流程时，就需要考虑算法在 AlphaMed 平台上实际运行时的情况了。此时会涉及节点集合同步、AlphaMed 平台要求等外部约束，需要一并考虑。\n",
    "\n",
    "加入外部约束后的流程为：\n",
    "1. 聚合方和所有参与方上线，初始化本地资源；（各参与方上线顺序是随机的，可能有各种情况。）\n",
    "2. 此时参与方还不知道聚合方是谁，所以广播发送集合请求；\n",
    "3. 聚合方收到集合请求后，记录参与者，并向请求方回复集合响应；\n",
    "4. 参与方收到集合响应后，记录聚合方，等待聚合方通知开始训练；\n",
    "5. 聚合方统计参与者数量，如果集合完成发送开始训练的通知；\n",
    "6. 开始训练后，聚合方、参与方完成初始化工作；\n",
    "7. 聚合方计数训练轮次，发送全局模型；\n",
    "8. 参与方接收全局模型，使用其更新本地模型；\n",
    "9. 参与方在本地做一个 epoch 的训练，更新本地模型；\n",
    "10. 参与方将本地模型发送给聚合方；\n",
    "11. 聚合方收集本地模型，集齐全部本地模型后，聚合得到新的全局模型；\n",
    "12. 聚合方检查训练轮次，判断训练是否完成；如果没有完成则跳到第 7 步，如果完成继续向下；\n",
    "13. 聚合方使用测试数据做一次测试，得到全局模型的评估指标数据；\n",
    "14. 聚合方上传模型文件和评估指标数据；\n",
    "15. 聚合方通知任务管理器训练结束，完成训练退出；\n",
    "16. 参与方收到训练结束的通知，完成训练退出。\n",
    "\n",
    "在此基础上可以拆解出聚合方、参与方各自的流程。\n",
    "\n",
    "聚合方流程为：\n",
    "1. 上线，初始化本地资源；\n",
    "2. 监听集合请求；\n",
    "3. 收到集合请求后，记录参与者，并向请求方回复集合响应；\n",
    "4. 统计参与者数量，如果集合完成发送开始训练的通知；\n",
    "5. 完成训练初始化工作；\n",
    "6. 计数训练轮次，发送全局模型；\n",
    "7. 监听本地模型传输请求，收集本地模型，集齐全部本地模型后，聚合得到新的全局模型；\n",
    "8. 检查训练轮次，判断训练是否完成；如果没有完成则跳到第 6 步，如果完成继续向下；\n",
    "9. 使用测试数据做一次测试，得到全局模型的评估指标数据；\n",
    "10. 上传模型文件和评估指标数据；\n",
    "11. 通知任务管理器训练结束，完成训练退出。\n",
    "\n",
    "参与方流程为：\n",
    "1. 上线，初始化本地资源；\n",
    "2. 此时还不知道聚合方是谁，所以广播发送集合请求；\n",
    "3. 监听集合响应，收到集合响应后，记录聚合方；\n",
    "4. 完成训练初始化工作；\n",
    "5. 监听开始训练消息或训练结束消息；如果收到开始训练消息，跳到第 6 步；如果收到训练结束消息，完成训练退出；\n",
    "6. 监听传输全局模型消息；\n",
    "7. 接收全局模型，使用其更新本地模型；\n",
    "8. 在本地做一个 epoch 的训练，更新本地模型；\n",
    "9. 将本地模型发送给聚合方；\n",
    "16. 跳到第 5 步。\n",
    "\n",
    "## 根据调度流程，定义用于互相协调的消息\n",
    "\n",
    "再贴一遍调度流程。\n",
    "1. 聚合方和所有参与方上线，初始化本地资源；（上线顺序随意，可能有各种情况）\n",
    "2. 此时参与方还不知道聚合方是谁，所以广播发送集合请求；\n",
    "3. 聚合方收到集合请求后，记录参与者，并向请求方回复集合响应；\n",
    "4. 参与方收到集合响应后，记录聚合方，等待聚合方通知开始训练；\n",
    "5. 聚合方统计参与者数量，如果集合完成发送开始训练的通知；\n",
    "6. 开始训练后，聚合方、参与方完成初始化工作；\n",
    "7. 聚合方计数训练轮次，发送全局模型；\n",
    "8. 参与方接收全局模型，使用其更新本地模型；\n",
    "9. 参与方在本地做一个 epoch 的训练，更新本地模型；\n",
    "10. 参与方将本地模型发送给聚合方；\n",
    "11. 聚合方收集本地模型，集齐全部本地模型后，聚合得到新的全局模型；\n",
    "12. 聚合方检查训练轮次，判断训练是否完成；如果没有完成则跳到第 7 步，如果完成继续向下；\n",
    "13. 聚合方使用测试数据做一次测试，得到全局模型的评估指标数据；\n",
    "14. 聚合方上传模型文件和评估指标数据；\n",
    "15. 聚合方通知任务管理器训练结束，完成训练退出；\n",
    "16. 参与方收到训练结束的通知，完成训练退出。\n",
    "\n",
    "根据调度流程，整理出需要以下消息来协调各方动作：集合请求消息、集合响应消息、开始训练消息、训练结束消息。\n",
    "\n",
    "## 实现合约消息体、消息工厂、消息发生工具\n",
    "\n",
    "参考[合约消息机制简介](6.%20%E5%90%88%E7%BA%A6%E6%B6%88%E6%81%AF%E6%9C%BA%E5%88%B6%E7%AE%80%E4%BB%8B.ipynb)，代码入下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from alphafed.contractor import ContractEvent\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CheckInEvent(ContractEvent):\n",
    "    \"\"\"集合请求消息。\"\"\"\n",
    "\n",
    "    TYPE = 'check_in'\n",
    "\n",
    "    peer_id: str\n",
    "\n",
    "    @classmethod\n",
    "    def contract_to_event(cls, contract: dict) -> 'CheckInEvent':\n",
    "        event_type = contract.get('type')\n",
    "        peer_id = contract.get('peer_id')\n",
    "        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'\n",
    "        assert peer_id and isinstance(peer_id, str), f'invalid peer_id: {peer_id}'\n",
    "        return CheckInEvent(peer_id=peer_id)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CheckInResponseEvent(ContractEvent):\n",
    "    \"\"\"集合响应消息。\"\"\"\n",
    "\n",
    "    TYPE = 'check_in_resp'\n",
    "\n",
    "    aggr_id: str\n",
    "\n",
    "    @classmethod\n",
    "    def contract_to_event(cls, contract: dict) -> 'CheckInResponseEvent':\n",
    "        event_type = contract.get('type')\n",
    "        aggr_id = contract.get('aggr_id')\n",
    "        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'\n",
    "        assert aggr_id and isinstance(aggr_id, str), f'invalid aggr_id: {aggr_id}'\n",
    "        return CheckInResponseEvent(aggr_id=aggr_id)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class StartEvent(ContractEvent):\n",
    "    \"\"\"开始训练消息。\"\"\"\n",
    "\n",
    "    TYPE = 'start'\n",
    "\n",
    "    @classmethod\n",
    "    def contract_to_event(cls, contract: dict) -> 'StartEvent':\n",
    "        event_type = contract.get('type')\n",
    "        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'\n",
    "        return StartEvent()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CloseEvent(ContractEvent):\n",
    "    \"\"\"训练结束消息。\"\"\"\n",
    "\n",
    "    TYPE = 'close'\n",
    "\n",
    "    @classmethod\n",
    "    def contract_to_event(cls, contract: dict) -> 'CloseEvent':\n",
    "        event_type = contract.get('type')\n",
    "        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'\n",
    "        return CloseEvent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphafed.contractor import TaskMessageEventFactory\n",
    "\n",
    "\n",
    "class SimpleFedAvgEventFactory(TaskMessageEventFactory):\n",
    "\n",
    "    _CLASS_MAP = {\n",
    "        CheckInEvent.TYPE: CheckInEvent,\n",
    "        CheckInResponseEvent.TYPE: CheckInResponseEvent,\n",
    "        StartEvent.TYPE: StartEvent,\n",
    "        CloseEvent.TYPE: CloseEvent,\n",
    "        **TaskMessageEventFactory._CLASS_MAP\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphafed.contractor import TaskMessageContractor\n",
    "\n",
    "class SimpleFedAvgContractor(TaskMessageContractor):\n",
    "\n",
    "    def __init__(self, task_id: str):\n",
    "        super().__init__(task_id=task_id)\n",
    "        self._event_factory = SimpleFedAvgEventFactory\n",
    "\n",
    "    def check_in(self, peer_id: str):\n",
    "        \"\"\"发送集合请求消息。\"\"\"\n",
    "        event = CheckInEvent(peer_id=peer_id)\n",
    "        self._new_contract(targets=self.EVERYONE, event=event)\n",
    "\n",
    "    def response_check_in(self, aggr_id: str, peer_id: str):\n",
    "        \"\"\"发送集合响应消息。\"\"\"\n",
    "        event = CheckInResponseEvent(aggr_id=aggr_id)\n",
    "        self._new_contract(targets=[peer_id], event=event)\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"发送开始训练消息。\"\"\"\n",
    "        event = StartEvent()\n",
    "        self._new_contract(targets=self.EVERYONE, event=event)\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"发送训练结束消息。\"\"\"\n",
    "        event = CloseEvent()\n",
    "        self._new_contract(targets=self.EVERYONE, event=event)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将合约消息代码整理好，集中放在一个 [contractor.py](res/simple_fed_avg/contractor.py) 文件中，方便使用。\n",
    "\n",
    "## 设计流程中需要用户实现的接口\n",
    "\n",
    "再贴一遍调度流程。\n",
    "1. 聚合方和所有参与方上线，初始化本地资源；（上线顺序随意，可能有各种情况）\n",
    "2. 此时参与方还不知道聚合方是谁，所以广播发送集合请求；\n",
    "3. 聚合方收到集合请求后，记录参与者，并向请求方回复集合响应；\n",
    "4. 参与方收到集合响应后，记录聚合方，等待聚合方通知开始训练；\n",
    "5. 聚合方统计参与者数量，如果集合完成发送开始训练的通知；\n",
    "6. 开始训练后，聚合方、参与方；\n",
    "7. 聚合方计数训练轮次，发送全局模型；\n",
    "8. 参与方接收全局模型，使用其更新本地模型；\n",
    "9. 参与方在本地做一个 epoch 的训练，更新本地模型；\n",
    "10. 参与方将本地模型发送给聚合方；\n",
    "11. 聚合方收集本地模型，集齐全部本地模型后，聚合得到新的全局模型；\n",
    "12. 聚合方检查训练轮次，判断训练是否完成；如果没有完成则跳到第 7 步，如果完成继续向下；\n",
    "13. 聚合方使用测试数据做一次测试，得到全局模型的评估指标数据；\n",
    "14. 聚合方上传模型文件和评估指标数据；\n",
    "15. 聚合方通知任务管理器训练结束，完成训练退出；\n",
    "16. 参与方收到训练结束的通知，完成训练退出。\n",
    "\n",
    "仔细梳理上述流程，可以整理出以下这些操作，是算法调度流程本身处理不了的，需要使用者提供对应的逻辑。那就将这些方法封装为接口，由使用者提供实现逻辑，而调度器只需要在对应的流程节点上调用即可。\n",
    "- 完成集合前初始化本地资源；\n",
    "- 训练开始前的初始化工作；\n",
    "- 获取训练使用的模型对象；\n",
    "- 完成一个 epoch 训练的逻辑；\n",
    "- 测试的逻辑。\n",
    "\n",
    "因此逐个定义接口。由于现在还没有涉及实现细节，可以先不考虑接口的具体参数，待将来实现时补充完善。注意这里只是简单的示例，因此没有对接口设计做优化。现实中设计真正可用的算法调度器时，设计者可以根据自身理解优化接口设计。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "@abstractmethod\n",
    "def before_check_in(self):\n",
    "    \"\"\"完成集合前初始化本地资源。\"\"\"\n",
    "\n",
    "@abstractmethod\n",
    "def before_training(self):\n",
    "    \"\"\"训练开始前的初始化工作。\"\"\"\n",
    "\n",
    "@property\n",
    "@abstractmethod\n",
    "def model(self):\n",
    "    \"\"\"获取训练使用的模型对象。\"\"\"\n",
    "\n",
    "@abstractmethod\n",
    "def train_an_epoch(self):\n",
    "    \"\"\"完成一个 epoch 训练的逻辑。\"\"\"\n",
    "\n",
    "@abstractmethod\n",
    "def test(self):\n",
    "    \"\"\"测试的逻辑。\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现流程调度代码逻辑\n",
    "\n",
    "调度器必须继承自 `Scheduler` 基础类，并且实现 `Scheduler` 中定义的接口，目前只需要实现 `_run` 一个接口。由于设计的是具体调度器实现的虚拟基础类，所以这里将其设置为一个 `ABCMeta` 类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphafed import logger\n",
    "from alphafed.scheduler import Scheduler\n",
    "from alphafed.data_channel import SharedFileDataChannel\n",
    "\n",
    "\n",
    "class SimpleFedAvgScheduler(Scheduler, metaclass=ABCMeta):\n",
    "\n",
    "    def __init__(self, rounds: int) -> None:\n",
    "        super().__init__()\n",
    "        # 自定义一些初始化参数，此处只定义了 rounds 一个参数，用于设置训练的轮数\n",
    "        self.rounds = rounds\n",
    "\n",
    "    def _run(self, id: str, task_id: str, is_initiator: bool = False, recover: bool = False):\n",
    "        \"\"\"运行调度器的入口。\n",
    "\n",
    "        实际运行时由任务管理器负责传入接口参数，模拟环境下需要调试者自行传入模拟值。\n",
    "\n",
    "        参数说明:\n",
    "            id: 当前节点 ID\n",
    "            task_id: 当前任务 ID\n",
    "            is_initiator: 当前节点是否是任务发起方\n",
    "            recover: 是否使用恢复模式启动\n",
    "        \"\"\"\n",
    "        # 先记录传入的参数，由于本示例不支持恢复模式，可以忽略 recover\n",
    "        self.id = id\n",
    "        self.task_id = task_id\n",
    "        self.is_initiator = is_initiator\n",
    "\n",
    "        # 发起方作为聚合方，其它节点作为参与方\n",
    "        if self.is_initiator:\n",
    "            self._run_as_aggregator()\n",
    "        else:\n",
    "            self._run_as_collaborator()\n",
    "\n",
    "    def _run_as_aggregator(self):\n",
    "        \"\"\"作为聚合方运行，具体实现后面介绍.\"\"\"\n",
    "        ...\n",
    "\n",
    "    def _run_as_collaborator(self):\n",
    "        \"\"\"作为参与方运行，具体实现后面介绍.\"\"\"\n",
    "        ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_run_as_aggregator` 和 `_run_as_collaborator` 接口都是算法设计者需要提供实现的接口，并不是给算法调度器的使用者（实际训练模型的开发者）实现的，也不希望他们修改实现，所以都定义为私有的。而上一步整理的 `before_check_in` 等五个接口才是需要由使用者提供实现的，所以定义为公有的。后面的接口设计采用同样的原则。\n",
    "\n",
    "然后把上一步整理定义的接口都加进去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "\n",
    "class SimpleFedAvgScheduler(Scheduler, metaclass=ABCMeta):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def before_check_in(self):\n",
    "        \"\"\"完成集合前初始化本地资源。\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def before_training(self):\n",
    "        \"\"\"训练开始前的初始化工作。\"\"\"\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def model(self) -> Module:\n",
    "        \"\"\"获取训练使用的模型对象。\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def train_an_epoch(self):\n",
    "        \"\"\"完成一个 epoch 训练的逻辑。\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def test(self):\n",
    "        \"\"\"测试的逻辑。\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以此为基础，可以开始逐步实现流程逻辑了。先考虑聚合方的情况，再贴一遍聚合方流程：\n",
    "1. 上线，初始化本地资源；\n",
    "2. 监听集合请求；\n",
    "3. 收到集合请求后，记录参与者，并向请求方回复集合响应；\n",
    "4. 统计参与者数量，如果集合完成发送开始训练的通知；\n",
    "5. 完成训练初始化工作；\n",
    "6. 计数训练轮次，发送全局模型；\n",
    "7. 监听本地模型传输请求，收集本地模型，集齐全部本地模型后，聚合得到新的全局模型；\n",
    "8. 检查训练轮次，判断训练是否完成；如果没有完成则跳到第 6 步，如果完成继续向下；\n",
    "9. 使用测试数据做一次测试，得到全局模型的评估指标数据；\n",
    "10. 上传模型文件和评估指标数据；\n",
    "11. 通知任务管理器训练结束，完成训练退出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from abc import ABCMeta\n",
    "from tempfile import TemporaryFile\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from alphafed.data_channel import SharedFileDataChannel\n",
    "from alphafed.fs import get_result_dir\n",
    "from alphafed.scheduler import Scheduler\n",
    "\n",
    "from .contractor import CheckInEvent, SimpleFedAvgContractor\n",
    "\n",
    "\n",
    "class SimpleFedAvgScheduler(Scheduler, metaclass=ABCMeta):\n",
    "\n",
    "    def _run_as_aggregator(self):\n",
    "        \"\"\"作为聚合方运行.\"\"\"\n",
    "        # 初始化本地资源\n",
    "        self.contractor = SimpleFedAvgContractor(task_id=self.task_id)\n",
    "        self.data_channel = SharedFileDataChannel(contractor=self.contractor)\n",
    "\n",
    "        self.collaborators = self.contractor.query_nodes()\n",
    "        self.collaborators.remove(self.id)  # 把自己移出去\n",
    "        self.checked_in = set()  # 记录集合的参与方\n",
    "        self.result_dir = get_result_dir(self.task_id)\n",
    "        self.log_dir = os.path.join(self.result_dir, 'tb_logs')  # 记录测试评估指标的目录\n",
    "        self.tb_writer = SummaryWriter(log_dir=self.log_dir)  # 记录测试评估指标的 writter\n",
    "\n",
    "        # 调用 before_check_in 执行用户自定义的额外初始化逻辑。\n",
    "        # 聚合方与参与方的初始化逻辑可能会不一样，所以加一个 is_aggregator 参数已做区分。接口定义也据此更新。\n",
    "        self.before_check_in(is_aggregator=True)\n",
    "        self.push_log(f'节点 {self.id} 初始化完毕。')\n",
    "\n",
    "        # 监听集合请求\n",
    "        self.push_log('开始等待参与成员集合 ...')\n",
    "        for _event in self.contractor.contract_events():\n",
    "            if isinstance(_event, CheckInEvent):\n",
    "                # 收到集合请求后，记录参与者，并向请求方回复集合响应\n",
    "                self.checked_in.add(_event.peer_id)\n",
    "                self.contractor.response_check_in(aggr_id=self.id, peer_id=_event.peer_id)\n",
    "                self.push_log(f'成员 {_event.peer_id} 加入。')\n",
    "                # 统计参与者数量，如果集合完成退出循环\n",
    "                if len(self.collaborators) == len(self.checked_in):\n",
    "                    break  # 退出监听循环\n",
    "        self.push_log(f'参与成员集合完毕，共有 {len(self.checked_in)} 位参与者。')\n",
    "\n",
    "        # 完成训练初始化工作\n",
    "        self.model  # 初始化模型\n",
    "        # 调用 before_training 执行用户自定义的额外初始化逻辑。\n",
    "        # 聚合方与参与方的初始化逻辑可能会不一样，所以加一个 is_aggregator 参数已做区分。接口定义也据此更新。\n",
    "        self.before_training(is_aggregator=True)\n",
    "        self.push_log(f'节点 {self.id} 准备就绪，可以开始执行计算任务。')\n",
    "\n",
    "        for _round in range(self.rounds):\n",
    "            # 发送开始训练的通知\n",
    "            self.contractor.start()\n",
    "            self.push_log(f'第 {_round + 1} 轮训练开始。')\n",
    "            # 计数训练轮次，发送全局模型\n",
    "            with TemporaryFile() as f:\n",
    "                torch.save(self.model.state_dict(), f)\n",
    "                f.seek(0)\n",
    "                self.push_log('开始发送全局模型 ...')\n",
    "                self.data_channel.batch_send_stream(source=self.id,\n",
    "                                                    target=self.collaborators,\n",
    "                                                    data_stream=f.read(),\n",
    "                                                    ensure_all_succ=True)\n",
    "            self.push_log('发送全局模型完成。')\n",
    "            # 监听本地模型传输请求，收集本地模型\n",
    "            self.updates = []  # 记录本地模型参数更新\n",
    "            self.push_log('开始等待收集本地模型 ...')\n",
    "            training_results = self.data_channel.batch_receive_stream(\n",
    "                receiver=self.id,\n",
    "                source_list=self.collaborators,\n",
    "                ensure_all_succ=True\n",
    "            )\n",
    "            for _source, _result in training_results.items():\n",
    "                buffer = io.BytesIO(_result)\n",
    "                state_dict = torch.load(buffer)\n",
    "                self.updates.append(state_dict)\n",
    "                self.push_log(f'收到来自 {_source} 的本地模型。')\n",
    "            # 聚合得到新的全局模型\n",
    "            self.push_log('开始执行参数聚合 ...')\n",
    "            self._make_aggregation()\n",
    "            self.push_log('参数聚合完成。')\n",
    "            # 如果达到训练轮次，循环结束\n",
    "\n",
    "        # 使用测试数据做一次测试，得到全局模型的评估指标数据\n",
    "        # 测试时指定 TensorBoard 的 writter，否则用户使用自定义的 writter，无法控制日志文件目录。\n",
    "        # 接口定义也据此更新。\n",
    "        self.push_log('训练完成，测试训练效果 ...')\n",
    "        self.run_test(writer=self.tb_writer)\n",
    "        self.push_log('测试完成。')\n",
    "\n",
    "        # 上传模型文件和评估指标数据\n",
    "        # 打包记录测试时写入的所有 TensorBoard 日志文件\n",
    "        self.push_log('整理计算结果，准备上传 ...')\n",
    "        report_file = os.path.join(self.result_dir, \"report.zip\")\n",
    "        with ZipFile(report_file, 'w') as report_zip:\n",
    "            for path, _, filenames in os.walk(self.log_dir):\n",
    "                rel_dir = os.path.relpath(path=path, start=self.result_dir)\n",
    "                rel_dir = rel_dir.lstrip('.')  # ./file => file\n",
    "                for _file in filenames:\n",
    "                    rel_path = os.path.join(rel_dir, _file)\n",
    "                    report_zip.write(os.path.join(path, _file), rel_path)\n",
    "        report_file_path = os.path.abspath(report_file)\n",
    "        # 记录训练后的模型参数\n",
    "        model_file = os.path.join(self.result_dir, \"model.pt\")\n",
    "        with open(model_file, 'wb') as f:\n",
    "            torch.save(self.model.state_dict(), f)\n",
    "        model_file_path = os.path.abspath(model_file)\n",
    "        # 调用接口执行上传\n",
    "        self.contractor.upload_task_achivement(aggregator=self.contractor.EVERYONE[0],\n",
    "                                               report_file=report_file_path,\n",
    "                                               model_file=model_file_path)\n",
    "        self.push_log('计算结果上传完成。')\n",
    "\n",
    "        # 通知任务管理器训练结束，完成训练退出\n",
    "        self.contractor.notify_task_completion(result=True)\n",
    "        self.contractor.close()\n",
    "        self.push_log('计算任务完成。')\n",
    "\n",
    "    def _make_aggregation(self):\n",
    "        \"\"\"执行参数聚合。\"\"\"\n",
    "        # 模型参数清零\n",
    "        global_params = self.model.state_dict()\n",
    "        for _param in global_params.values():\n",
    "            if isinstance(_param, torch.Tensor):\n",
    "                _param.zero_()\n",
    "        # 累加收到的本地模型参数\n",
    "        for _update in self.updates:\n",
    "            for _key in global_params.keys():\n",
    "                global_params[_key].add_(_update[_key])\n",
    "        # 求平均值获得新的全局参数\n",
    "        count = len(self.collaborators)\n",
    "        for _key in global_params.keys():\n",
    "            if global_params[_key].dtype in (\n",
    "                torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64\n",
    "            ):\n",
    "                global_params[_key].div_(count, rounding_mode='trunc')\n",
    "            else:\n",
    "                global_params[_key].div_(count)\n",
    "        self.model.load_state_dict(global_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来实现参与方的调度流程，再贴一遍参与方流程：\n",
    "1. 上线，初始化本地资源；\n",
    "2. 此时还不知道聚合方是谁，所以广播发送集合请求；\n",
    "3. 监听集合响应，收到集合响应后，记录聚合方；\n",
    "4. 完成训练初始化工作；\n",
    "5. 监听开始训练消息或训练结束消息；如果收到开始训练消息，跳到第 6 步；如果收到训练结束消息，完成训练退出；\n",
    "6. 监听传输全局模型消息；\n",
    "7. 接收全局模型，使用其更新本地模型；\n",
    "8. 在本地做一个 epoch 的训练，更新本地模型；\n",
    "9. 将本地模型发送给聚合方；\n",
    "16. 跳到第 5 步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta\n",
    "import io\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "import torch\n",
    "\n",
    "from alphafed.data_channel import SharedFileDataChannel\n",
    "from alphafed.scheduler import Scheduler\n",
    "\n",
    "from .contractor import (CheckInResponseEvent, CloseEvent,\n",
    "                         SimpleFedAvgContractor, StartEvent)\n",
    "\n",
    "\n",
    "class SimpleFedAvgScheduler(Scheduler, metaclass=ABCMeta):\n",
    "\n",
    "    def _run_as_collaborator(self):\n",
    "        \"\"\"作为参与方运行。\"\"\"\n",
    "        # 初始化本地资源\n",
    "        self.contractor = SimpleFedAvgContractor(task_id=self.task_id)\n",
    "        self.data_channel = SharedFileDataChannel(contractor=self.contractor)\n",
    "\n",
    "        # 调用 before_check_in 执行用户自定义的额外初始化逻辑。\n",
    "        # 聚合方与参与方的初始化逻辑可能会不一样，所以加一个 is_aggregator 参数已做区分。接口定义也据此更新。\n",
    "        self.before_check_in(is_aggregator=False)\n",
    "        self.push_log(f'节点 {self.id} 初始化完毕。')\n",
    "\n",
    "        # 广播发送集合请求\n",
    "        self.push_log('发送集合请求，等待聚合方响应。')\n",
    "        self.contractor.check_in(peer_id=self.id)\n",
    "        # 监听集合响应，收到集合响应后，记录聚合方\n",
    "        for _event in self.contractor.contract_events():\n",
    "            if isinstance(_event, CheckInResponseEvent):\n",
    "                self.aggregator = _event.aggr_id\n",
    "                self.push_log('收到响应，集合成功。')\n",
    "                break  # 退出监听循环\n",
    "\n",
    "        # 完成训练初始化工作\n",
    "        self.model  # 初始化模型\n",
    "        # 调用 before_training 执行用户自定义的额外初始化逻辑。\n",
    "        # 聚合方与参与方的初始化逻辑可能会不一样，所以加一个 is_aggregator 参数已做区分。接口定义也据此更新。\n",
    "        self.before_training(is_aggregator=False)\n",
    "        self.push_log(f'节点 {self.id} 准备就绪，可以开始执行计算任务。')\n",
    "\n",
    "        while True:\n",
    "            self.push_log('等待训练开始信号 ...')\n",
    "            # 监听开始训练消息或训练结束消息；如果收到开始训练消息，跳到第 6 步；如果收到训练结束消息，完成训练退出\n",
    "            for _event in self.contractor.contract_events():\n",
    "                if isinstance(_event, StartEvent):\n",
    "                    self.push_log('开始训练 ...')\n",
    "                    break  # 退出监听循环\n",
    "                elif isinstance(_event, CloseEvent):\n",
    "                    self.push_log('训练完成。')\n",
    "                    return  # 退出训练\n",
    "            # 监听传输全局模型消息\n",
    "            self.push_log('等待接收全局模型 ...')\n",
    "            _, data_stream = self.data_channel.receive_stream(receiver=self.id,\n",
    "                                                              source=self.aggregator)\n",
    "            buffer = io.BytesIO(data_stream)\n",
    "            new_state = torch.load(buffer)\n",
    "            self.model.load_state_dict(new_state)\n",
    "            self.push_log('接收全局模型成功。')\n",
    "            # 在本地做一个 epoch 的训练，更新本地模型\n",
    "            self.push_log('开始训练本地模型 ...')\n",
    "            self.train_an_epoch()\n",
    "            self.push_log('训练本地模型完成。')\n",
    "            # 将本地模型发送给聚合方\n",
    "            with TemporaryFile() as f:\n",
    "                torch.save(self.model.state_dict(), f)\n",
    "                f.seek(0)\n",
    "                self.push_log('准备发送本地模型 ...')\n",
    "                self.data_channel.send_stream(source=self.id,\n",
    "                                              target=self.aggregator,\n",
    "                                              data_stream=f.read())\n",
    "                self.push_log('发送本地模型完成。')\n",
    "            # 继续循环"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，自定义的极简 FedAvg 算法调度器就实现了。将上面的代码整理好之后保存在一个 [scheduler.py](res/simple_fed_avg/scheduler.py) 文件中。之后会演示如何使用这个算法调度器训练模型。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Oct 12 2021, 06:23:56) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
