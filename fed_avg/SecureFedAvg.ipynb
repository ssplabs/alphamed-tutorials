{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建你的第一个 Secure Aggregation FedAvg 联邦学习任务\n",
    "\n",
    "Secure Aggregation FedAvg 算法（以下简称 SecureFedAvg 算法）是 FedAvg 算法的一个扩展，在原算法基础上提供了隐私参数的支持。如果你对 FedAvg 算法及其使用方式还不了解，请先移步至[创建你的第一个 FedAvg 联邦学习任务](FedAvg.ipynb)，然后再回来继续阅读。\n",
    "\n",
    "SecureFedAvg 算法是 FedAvg 算法的一个扩展，因此二者的大部分内容是相同的，所以这里只介绍二者存在差异的部分。\n",
    "\n",
    "### 初始化参数\n",
    "\n",
    "SecureFedAvg 需要一个额外的超参数 t，用于控制秘密共享时恢复秘密所需的最少秘密切片数量。以下代码展示了如何定义一个 SecureFedAvg 算法的实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from alphafed import logger\n",
    "from alphafed.fed_avg import SecureFedAvgScheduler\n",
    "\n",
    "class DemoSecureFedAvg(SecureFedAvgScheduler):\n",
    "    ...\n",
    "\n",
    "\n",
    "scheduler = DemoSecureFedAvg(t=2,\n",
    "                             max_rounds=5,\n",
    "                             log_rounds=1,\n",
    "                             calculation_timeout=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SecureFedAvg 算法其余部分的实现方式和要求与 FedAvg 算法完全一致，请参考 FedAvg 算法部分的说明。下面是一个完整的 SecureFedAvg 算法示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from alphafed import get_dataset_dir, logger\n",
    "from alphafed.fed_avg import SecureFedAvgScheduler\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(in_features=320, out_features=50)\n",
    "        self.fc2 = nn.Linear(in_features=50, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "\n",
    "class DemoSecureFedAvg(SecureFedAvgScheduler):\n",
    "\n",
    "    def __init__(self,\n",
    "                 t: int,\n",
    "                 max_rounds: int = 0,\n",
    "                 merge_epoch: int = 1,\n",
    "                 calculation_timeout: int = 300,\n",
    "                 log_rounds: int = 0) -> None:\n",
    "        super().__init__(t=t,\n",
    "                         max_rounds=max_rounds,\n",
    "                         merge_epochs=merge_epoch,\n",
    "                         calculation_timeout=calculation_timeout,\n",
    "                         log_rounds=log_rounds)\n",
    "        self.batch_size = 64\n",
    "        self.learning_rate = 0.01\n",
    "        self.momentum = 0.5\n",
    "        self.log_interval = 5\n",
    "        self.random_seed = 42\n",
    "\n",
    "        torch.manual_seed(self.random_seed)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def build_model(self) -> nn.Module:\n",
    "        model = ConvNet()\n",
    "        return model.to(self.device)\n",
    "\n",
    "    def build_optimizer(self, model: nn.Module) -> optim.Optimizer:\n",
    "        return optim.SGD(model.parameters(),\n",
    "                        lr=self.learning_rate,\n",
    "                        momentum=self.momentum)\n",
    "\n",
    "    def build_train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            torchvision.datasets.MNIST(\n",
    "                get_dataset_dir(self.task_id),\n",
    "                train=True,\n",
    "                download=True,\n",
    "                transform=torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                ])\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "    def build_test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            torchvision.datasets.MNIST(\n",
    "                get_dataset_dir(self.task_id),\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                ])\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "    def state_dict(self) -> Dict[str, torch.Tensor]:\n",
    "        return self.model.state_dict()\n",
    "\n",
    "    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):\n",
    "        self.model.load_state_dict(state_dict)\n",
    "\n",
    "    def validate_context(self):\n",
    "        super().validate_context()\n",
    "        assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'\n",
    "        self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')\n",
    "        assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'\n",
    "        self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')\n",
    "\n",
    "    def train_an_epoch(self) -> None:\n",
    "        self.model.train()\n",
    "        for data, labels in self.train_loader:\n",
    "            data: torch.Tensor\n",
    "            labels: torch.Tensor\n",
    "            data, labels = data.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = F.nll_loss(output, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def run_test(self):\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, labels in self.test_loader:\n",
    "                data: torch.Tensor\n",
    "                labels: torch.Tensor\n",
    "                data, labels = data.to(self.device), labels.to(self.device)\n",
    "                output: torch.Tensor = self.model(data)\n",
    "                test_loss += F.nll_loss(output, labels, reduction='sum').item()\n",
    "                pred = output.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(self.test_loader.dataset)\n",
    "        correct_rate = 100. * correct / len(self.test_loader.dataset)\n",
    "        logger.info(f'Test set: Average loss: {test_loss:.4f}')\n",
    "        logger.info(\n",
    "            f'Test set: Accuracy: {correct}/{len(self.test_loader.dataset)} ({correct_rate:.2f}%)'\n",
    "        )\n",
    "\n",
    "\n",
    "scheduler = DemoSecureFedAvg(t=2,\n",
    "                             max_rounds=5,\n",
    "                             log_rounds=1,\n",
    "                             calculation_timeout=120)\n",
    "scheduler.submit(task_id='YOUR_TASK_ID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
